#!/usr/bin/env python3
"""
–î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –ø—Ä–æ–±–ª–µ–º —Å LLM
"""

import asyncio
import os

import aiohttp


async def test_llm_directly():
    """–ü—Ä—è–º–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ LLM –ø—Ä–æ–∫—Å–∏"""

    print("üîç –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ LLM")
    print("=" * 40)

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
    api_key = os.getenv("LLM_API_KEY")
    proxy_url = os.getenv("LLM_PROXY_URL")
    model = os.getenv("LLM_MODEL", "gpt-4")

    print(f"API Key: {api_key[:10]}..." if api_key else "–Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
    print(f"Proxy URL: {proxy_url}")
    print(f"Model: {model}")

    if not api_key or not proxy_url:
        print("‚ùå –ù–µ —Ö–≤–∞—Ç–∞–µ—Ç –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è")
        return

    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø—Ä—è–º–æ–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ LLM –ø—Ä–æ–∫—Å–∏
    print("\nüß™ –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø—Ä—è–º–æ–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ LLM...")

    headers = {"Authorization": f"Bearer {api_key}", "Content-Type": "application/json"}

    payload = {
        "model": model,
        "messages": [
            {
                "role": "system",
                "content": "–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –∞–ª–µ—Ä—Ç–æ–≤. –ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–π —ç—Ç–æ—Ç –∞–ª–µ—Ä—Ç.",
            },
            {"role": "user", "content": "High CPU usage detected on web-server-1"},
        ],
        "max_tokens": 100,
    }

    try:
        async with aiohttp.ClientSession() as session:
            print(f"üì§ –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å –∫ {proxy_url}/v1/chat/completions")

            async with session.post(
                f"{proxy_url}/v1/chat/completions",
                headers=headers,
                json=payload,
                timeout=aiohttp.ClientTimeout(total=30),
            ) as response:
                print(f"üì• –ü–æ–ª—É—á–µ–Ω –æ—Ç–≤–µ—Ç: {response.status}")

                if response.status == 200:
                    data = await response.json()
                    print("‚úÖ LLM –æ—Ç–≤–µ—Ç–∏–ª —É—Å–ø–µ—à–Ω–æ!")
                    if "choices" in data and len(data["choices"]) > 0:
                        content = data["choices"][0]["message"]["content"]
                        print(f"üìù –û—Ç–≤–µ—Ç: {content[:200]}...")
                else:
                    text = await response.text()
                    print(f"‚ùå –û—à–∏–±–∫–∞: {response.status}")
                    print(f"üìù –û—Ç–≤–µ—Ç: {text}")

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è: {e}")


def test_llm_client():
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ LLM –∫–ª–∏–µ–Ω—Ç–∞"""

    print("\nüîß –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ LLM –∫–ª–∏–µ–Ω—Ç–∞...")

    try:
        from datetime import datetime

        from src.alert_history.core.interfaces import Alert, AlertStatus
        from src.alert_history.services.llm_client import LLMProxyClient

        # –°–æ–∑–¥–∞–µ–º LLM –∫–ª–∏–µ–Ω—Ç
        llm_client = LLMProxyClient(
            proxy_url=os.getenv("LLM_PROXY_URL"),
            api_key=os.getenv("LLM_API_KEY"),
            model=os.getenv("LLM_MODEL", "gpt-4"),
            timeout=int(os.getenv("LLM_TIMEOUT", "30")),
            max_retries=int(os.getenv("LLM_MAX_RETRIES", "3")),
        )

        print("‚úÖ LLM –∫–ª–∏–µ–Ω—Ç —Å–æ–∑–¥–∞–Ω")

        # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–π –∞–ª–µ—Ä—Ç
        test_alert = Alert(
            fingerprint="test-debug",
            alert_name="TestAlert",
            status=AlertStatus.FIRING,
            labels={"instance": "test-server", "severity": "warning"},
            annotations={"description": "Test alert for debugging"},
            starts_at=datetime.now(),
            generator_url="http://localhost:9090",
        )

        print("‚úÖ –¢–µ—Å—Ç–æ–≤—ã–π –∞–ª–µ—Ä—Ç —Å–æ–∑–¥–∞–Ω")

        # –¢–µ—Å—Ç–∏—Ä—É–µ–º –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—é
        print("üì§ –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å –Ω–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—é...")
        result = asyncio.run(llm_client.classify_alert(test_alert))

        if result:
            print("‚úÖ –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —É—Å–ø–µ—à–Ω–∞!")
            print(f"üìù –†–µ–∑—É–ª—å—Ç–∞—Ç: {result}")
        else:
            print("‚ùå –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –Ω–µ —É–¥–∞–ª–∞—Å—å")

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ LLM –∫–ª–∏–µ–Ω—Ç–∞: {e}")
        import traceback

        traceback.print_exc()


if __name__ == "__main__":
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø—Ä—è–º–æ–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ
    asyncio.run(test_llm_directly())

    # –¢–µ—Å—Ç–∏—Ä—É–µ–º LLM –∫–ª–∏–µ–Ω—Ç
    test_llm_client()
