# TN-147: POST /api/v2/alerts Endpoint â€” Technical Design

> **ĞÑ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ°**: HTTP Handler â†’ Parser (TN-146) â†’ Validator â†’ AlertProcessor â†’ Response
> **Ğ¦ĞµĞ»ÑŒ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ°**: 150% (Grade A+ EXCEPTIONAL)
> **Ğ¡Ñ‚Ğ°Ñ‚ÑƒÑ**: ğŸ¯ DESIGN COMPLETE, READY FOR IMPLEMENTATION

---

## ğŸ“‹ ĞĞ³Ğ»Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ

1. [Architecture Overview](#architecture-overview)
2. [Component Design](#component-design)
3. [Data Flow](#data-flow)
4. [Interface Specifications](#interface-specifications)
5. [Error Handling Strategy](#error-handling-strategy)
6. [Performance Optimization](#performance-optimization)
7. [Observability Design](#observability-design)
8. [Testing Strategy](#testing-strategy)
9. [Integration Points](#integration-points)
10. [Implementation Checklist](#implementation-checklist)

---

## Architecture Overview

### High-Level Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Prometheus Server(s)                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚ HTTP POST
                      â”‚ /api/v2/alerts
                      â”‚ Content-Type: application/json
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Alert History Service (Go)                      â”‚
â”‚                                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚           HTTP Server (net/http.ServeMux)                  â”‚ â”‚
â”‚  â”‚  Route: POST /api/v2/alerts â†’ PrometheusAlertsHandler     â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                       â”‚                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚      PrometheusAlertsHandler (TN-147 - THIS TASK)         â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚
â”‚  â”‚  â”‚ 1. Read Request Body (io.ReadAll)                    â”‚ â”‚ â”‚
â”‚  â”‚  â”‚ 2. Parse JSON â†’ PrometheusWebhook (TN-146)           â”‚ â”‚ â”‚
â”‚  â”‚  â”‚ 3. Validate Structure (TN-043)                       â”‚ â”‚ â”‚
â”‚  â”‚  â”‚ 4. Convert to []core.Alert                           â”‚ â”‚ â”‚
â”‚  â”‚  â”‚ 5. Process each alert (AlertProcessor)               â”‚ â”‚ â”‚
â”‚  â”‚  â”‚ 6. Build Response (200/207/400/500)                  â”‚ â”‚ â”‚
â”‚  â”‚  â”‚ 7. Record Metrics (Prometheus)                       â”‚ â”‚ â”‚
â”‚  â”‚  â”‚ 8. Log Results (slog)                                â”‚ â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                       â”‚                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚    PrometheusParser (TN-146) - DEPENDENCY âœ…               â”‚ â”‚
â”‚  â”‚  â€¢ DetectFormat(data) â†’ v1 / v2                          â”‚ â”‚
â”‚  â”‚  â€¢ Parse(data) â†’ *AlertmanagerWebhook                    â”‚ â”‚
â”‚  â”‚  â€¢ Validate(webhook) â†’ *ValidationResult                 â”‚ â”‚
â”‚  â”‚  â€¢ ConvertToDomain(webhook) â†’ []*core.Alert              â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                       â”‚                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚      AlertProcessor (TN-061) - DEPENDENCY âœ…               â”‚ â”‚
â”‚  â”‚  ProcessAlert(ctx, alert) â†’ error                         â”‚ â”‚
â”‚  â”‚    â”œâ”€ Deduplication (TN-036)                              â”‚ â”‚
â”‚  â”‚    â”œâ”€ Inhibition Check (TN-130)                           â”‚ â”‚
â”‚  â”‚    â”œâ”€ Enrichment (TN-033/034, optional)                   â”‚ â”‚
â”‚  â”‚    â”œâ”€ Filtering (TN-035, optional)                        â”‚ â”‚
â”‚  â”‚    â”œâ”€ Storage (TN-032)                                    â”‚ â”‚
â”‚  â”‚    â””â”€ Publishing (TN-051-060, optional)                   â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Component Responsibilities

| Component | Responsibility | Complexity |
|-----------|----------------|------------|
| **PrometheusAlertsHandler** | HTTP endpoint, orchestration | Medium |
| **PrometheusParser (TN-146)** | Format detection, parsing, conversion | High (DONE) |
| **WebhookValidator (TN-043)** | Validation rules | Medium (DONE) |
| **AlertProcessor (TN-061)** | Processing pipeline | High (DONE) |
| **Response Builder** | Format HTTP responses | Low |
| **Metrics Collector** | Record Prometheus metrics | Low |

**TN-147 Focus**: Ğ¢Ğ¾Ğ»ÑŒĞºĞ¾ **PrometheusAlertsHandler** + **Response Builder** + **Metrics** (Ğ²ÑĞµ Ğ¾ÑÑ‚Ğ°Ğ»ÑŒĞ½Ğ¾Ğµ ÑƒĞ¶Ğµ Ğ³Ğ¾Ñ‚Ğ¾Ğ²Ğ¾!)

---

## Component Design

### 1. PrometheusAlertsHandler

**Location**: `go-app/cmd/server/handlers/prometheus_alerts.go`

**Struct Definition**:
```go
package handlers

import (
    "context"
    "encoding/json"
    "io"
    "log/slog"
    "net/http"
    "time"

    "github.com/vitaliisemenov/alert-history/internal/core"
    "github.com/vitaliisemenov/alert-history/internal/infrastructure/webhook"
    "github.com/vitaliisemenov/alert-history/pkg/metrics"
)

// PrometheusAlertsHandler handles POST /api/v2/alerts endpoint.
//
// This handler provides Alertmanager-compatible API for receiving alerts
// directly from Prometheus servers. It supports both Prometheus v1 and v2
// alert formats and processes them through the full AlertProcessor pipeline.
//
// Architecture:
//   HTTP Request â†’ Parse (TN-146) â†’ Validate â†’ Process â†’ Response
//
// Performance targets (150% quality):
//   - p95 latency: < 5ms
//   - Throughput: 2,000+ req/s
//   - Memory: < 5 KB per request
//
// Compatibility:
//   - Prometheus v1 alert format (array)
//   - Prometheus v2 alert format (grouped)
//   - Alertmanager API v2 response format
type PrometheusAlertsHandler struct {
    parser     webhook.WebhookParser      // TN-146: Prometheus parser
    processor  AlertProcessor              // TN-061: Alert processing pipeline
    metrics    *PrometheusAlertsMetrics   // TN-147: Endpoint metrics
    logger     *slog.Logger                // Structured logging
    config     *PrometheusAlertsConfig    // Handler configuration
}

// PrometheusAlertsConfig holds configuration for the handler.
type PrometheusAlertsConfig struct {
    MaxRequestSize   int64         // Max request body size (default: 10 MB)
    RequestTimeout   time.Duration // Max request processing time (default: 30s)
    MaxAlertsPerReq  int           // Max alerts per request (default: 1000)
    EnableMetrics    bool          // Enable Prometheus metrics (default: true)
    ReturnPartial    bool          // Return 207 on partial success (default: true)
}

// DefaultPrometheusAlertsConfig returns default configuration.
func DefaultPrometheusAlertsConfig() *PrometheusAlertsConfig {
    return &PrometheusAlertsConfig{
        MaxRequestSize:  10 * 1024 * 1024, // 10 MB
        RequestTimeout:  30 * time.Second,
        MaxAlertsPerReq: 1000,
        EnableMetrics:   true,
        ReturnPartial:   true,
    }
}
```

**Constructor**:
```go
// NewPrometheusAlertsHandler creates a new Prometheus alerts handler.
//
// This handler requires:
//   - parser: TN-146 PrometheusParser for parsing v1/v2 formats
//   - processor: AlertProcessor for processing pipeline
//   - logger: Structured logger
//
// Optional:
//   - config: Handler configuration (uses defaults if nil)
//
// Returns:
//   - *PrometheusAlertsHandler: Initialized handler
//   - error: Configuration error (if any)
func NewPrometheusAlertsHandler(
    parser webhook.WebhookParser,
    processor AlertProcessor,
    logger *slog.Logger,
    config *PrometheusAlertsConfig,
) (*PrometheusAlertsHandler, error) {
    // Validate dependencies
    if parser == nil {
        return nil, fmt.Errorf("parser is required")
    }
    if processor == nil {
        return nil, fmt.Errorf("processor is required")
    }
    if logger == nil {
        logger = slog.Default()
    }
    if config == nil {
        config = DefaultPrometheusAlertsConfig()
    }

    // Initialize metrics
    var metricsCollector *PrometheusAlertsMetrics
    if config.EnableMetrics {
        metricsCollector = NewPrometheusAlertsMetrics()
    }

    return &PrometheusAlertsHandler{
        parser:    parser,
        processor: processor,
        metrics:   metricsCollector,
        logger:    logger,
        config:    config,
    }, nil
}
```

**Main Handler Method**:
```go
// HandlePrometheusAlerts handles POST /api/v2/alerts requests.
//
// Request flow:
//   1. Validate HTTP method (POST only)
//   2. Read and validate request body size
//   3. Parse JSON (Prometheus v1/v2 format via TN-146)
//   4. Validate alert structure (via TN-043)
//   5. Convert to domain models (via TN-146)
//   6. Process each alert (via AlertProcessor)
//   7. Build response (200/207/400/500)
//   8. Record metrics and log results
//
// HTTP Status Codes:
//   - 200: All alerts processed successfully
//   - 207: Partial success (some alerts failed)
//   - 400: Validation failed (bad request)
//   - 405: Method not allowed (non-POST)
//   - 413: Payload too large
//   - 500: Internal server error
//
// Performance:
//   - Target: < 5ms p95 latency (150% quality)
//   - Benchmark: See prometheus_alerts_bench_test.go
func (h *PrometheusAlertsHandler) HandlePrometheusAlerts(w http.ResponseWriter, r *http.Request) {
    startTime := time.Now()
    ctx := r.Context()

    // Add request timeout
    if h.config.RequestTimeout > 0 {
        var cancel context.CancelFunc
        ctx, cancel = context.WithTimeout(ctx, h.config.RequestTimeout)
        defer cancel()
    }

    // Log incoming request
    h.logger.Info("Prometheus alerts request received",
        "method", r.Method,
        "path", r.URL.Path,
        "remote_addr", r.RemoteAddr,
        "content_length", r.ContentLength,
    )

    // Step 1: Validate HTTP method
    if r.Method != http.MethodPost {
        h.respondError(w, http.StatusMethodNotAllowed, "method not allowed", nil)
        h.recordMetrics("validation_failed", "method_not_allowed", 0, time.Since(startTime))
        return
    }

    // Step 2: Read request body with size limit
    body, err := h.readRequestBody(r)
    if err != nil {
        h.respondError(w, http.StatusBadRequest, "failed to read request body", err)
        h.recordMetrics("validation_failed", "read_body_error", 0, time.Since(startTime))
        return
    }

    // Step 3: Parse Prometheus alerts (v1 or v2 format)
    webhook, err := h.parser.Parse(body)
    if err != nil {
        h.logger.Error("Failed to parse Prometheus webhook", "error", err)
        h.respondError(w, http.StatusBadRequest, "failed to parse webhook", err)
        h.recordMetrics("validation_failed", "parse_error", 0, time.Since(startTime))
        return
    }

    // Step 4: Validate webhook structure
    validationResult := h.parser.Validate(webhook)
    if !validationResult.Valid {
        h.logger.Warn("Webhook validation failed", "errors", validationResult.Errors)
        h.respondValidationError(w, validationResult)
        h.recordMetrics("validation_failed", "validation_error", 0, time.Since(startTime))
        return
    }

    // Step 5: Convert to domain models
    alerts, err := h.parser.ConvertToDomain(webhook)
    if err != nil {
        h.logger.Error("Failed to convert webhook to domain", "error", err)
        h.respondError(w, http.StatusUnprocessableEntity, "failed to convert alerts", err)
        h.recordMetrics("validation_failed", "conversion_error", 0, time.Since(startTime))
        return
    }

    receivedCount := len(alerts)
    h.logger.Info("Alerts parsed successfully",
        "received_count", receivedCount,
        "format", webhook.Version, // "prom_v1" or "prom_v2"
    )

    // Step 6: Check alert count limit
    if receivedCount > h.config.MaxAlertsPerReq {
        h.respondError(w, http.StatusRequestEntityTooLarge,
            fmt.Sprintf("too many alerts (max: %d)", h.config.MaxAlertsPerReq), nil)
        h.recordMetrics("validation_failed", "too_many_alerts", receivedCount, time.Since(startTime))
        return
    }

    // Step 7: Process alerts through AlertProcessor pipeline
    processedCount, failedAlerts := h.processAlerts(ctx, alerts)

    duration := time.Since(startTime)

    // Step 8: Build and send response
    if len(failedAlerts) == 0 {
        // All alerts processed successfully â†’ 200 OK
        h.respondSuccess(w, receivedCount, processedCount, duration)
        h.recordMetrics("success", "all_processed", receivedCount, duration)
    } else if processedCount > 0 {
        // Partial success â†’ 207 Multi-Status
        h.respondPartialSuccess(w, receivedCount, processedCount, failedAlerts, duration)
        h.recordMetrics("partial", "some_failed", receivedCount, duration)
    } else {
        // All alerts failed â†’ 500 Internal Server Error
        h.respondError(w, http.StatusInternalServerError, "all alerts failed to process", nil)
        h.recordMetrics("error", "all_failed", receivedCount, duration)
    }

    h.logger.Info("Request processing complete",
        "received", receivedCount,
        "processed", processedCount,
        "failed", len(failedAlerts),
        "duration_ms", duration.Milliseconds(),
    )
}
```

**Helper Methods**:
```go
// readRequestBody reads and validates request body size.
func (h *PrometheusAlertsHandler) readRequestBody(r *http.Request) ([]byte, error) {
    // Check Content-Length header
    if r.ContentLength > h.config.MaxRequestSize {
        return nil, fmt.Errorf("request body too large: %d bytes (max: %d)",
            r.ContentLength, h.config.MaxRequestSize)
    }

    // Read body with size limit (defense in depth)
    limitedReader := io.LimitReader(r.Body, h.config.MaxRequestSize+1)
    body, err := io.ReadAll(limitedReader)
    if err != nil {
        return nil, fmt.Errorf("failed to read body: %w", err)
    }

    // Check actual size
    if int64(len(body)) > h.config.MaxRequestSize {
        return nil, fmt.Errorf("request body too large: %d bytes (max: %d)",
            len(body), h.config.MaxRequestSize)
    }

    if len(body) == 0 {
        return nil, fmt.Errorf("request body is empty")
    }

    return body, nil
}

// processAlerts processes alerts through AlertProcessor pipeline.
//
// Processing strategy:
//   - Best-effort: Continue processing even if some alerts fail
//   - Sequential: Process alerts in order (preserves temporal ordering)
//   - Collect failures: Track which alerts failed and why
//
// Returns:
//   - processedCount: Number of successfully processed alerts
//   - failedAlerts: List of alerts that failed processing
func (h *PrometheusAlertsHandler) processAlerts(
    ctx context.Context,
    alerts []*core.Alert,
) (int, []AlertFailure) {
    processedCount := 0
    failedAlerts := make([]AlertFailure, 0)

    for i, alert := range alerts {
        // Process alert through pipeline
        err := h.processor.ProcessAlert(ctx, alert)
        if err != nil {
            // Log error but continue processing
            h.logger.Warn("Alert processing failed",
                "index", i,
                "fingerprint", alert.Fingerprint,
                "alertname", alert.AlertName,
                "error", err,
            )

            failedAlerts = append(failedAlerts, AlertFailure{
                Index:       i,
                Fingerprint: alert.Fingerprint,
                AlertName:   alert.AlertName,
                Error:       err.Error(),
            })
            continue
        }

        processedCount++
    }

    return processedCount, failedAlerts
}
```

---

### 2. Response Builder

**Data Structures**:
```go
// PrometheusAlertsResponse represents successful response.
type PrometheusAlertsResponse struct {
    Status string                     `json:"status"` // "success" or "partial"
    Data   PrometheusAlertsResultData `json:"data"`
}

// PrometheusAlertsResultData contains processing results.
type PrometheusAlertsResultData struct {
    Received  int            `json:"received"`            // Total alerts received
    Processed int            `json:"processed"`           // Successfully processed
    Stored    int            `json:"stored,omitempty"`    // Stored in database
    Failed    int            `json:"failed,omitempty"`    // Failed to process
    Errors    []AlertFailure `json:"errors,omitempty"`    // Error details
    Timestamp string         `json:"timestamp"`           // Response timestamp (RFC3339)
}

// AlertFailure represents a failed alert.
type AlertFailure struct {
    Index       int    `json:"index"`                 // Alert index in request
    Fingerprint string `json:"fingerprint,omitempty"` // Alert fingerprint
    AlertName   string `json:"alertname,omitempty"`   // Alert name
    Error       string `json:"error"`                 // Error message
}

// PrometheusAlertsErrorResponse represents error response.
type PrometheusAlertsErrorResponse struct {
    Status string                     `json:"status"` // "error"
    Error  string                     `json:"error"`  // Error message
    Errors []ValidationError          `json:"errors,omitempty"` // Validation errors
}

// ValidationError represents a single validation error.
type ValidationError struct {
    Field   string      `json:"field"`             // Field path (e.g., "alerts[0].labels.alertname")
    Message string      `json:"message"`           // Error message
    Value   interface{} `json:"value,omitempty"`   // Invalid value
}
```

**Response Methods**:
```go
// respondSuccess sends 200 OK response.
func (h *PrometheusAlertsHandler) respondSuccess(
    w http.ResponseWriter,
    received, processed int,
    duration time.Duration,
) {
    response := PrometheusAlertsResponse{
        Status: "success",
        Data: PrometheusAlertsResultData{
            Received:  received,
            Processed: processed,
            Stored:    processed, // Assume stored = processed
            Timestamp: time.Now().Format(time.RFC3339),
        },
    }

    w.Header().Set("Content-Type", "application/json")
    w.WriteHeader(http.StatusOK)
    json.NewEncoder(w).Encode(response)
}

// respondPartialSuccess sends 207 Multi-Status response.
func (h *PrometheusAlertsHandler) respondPartialSuccess(
    w http.ResponseWriter,
    received, processed int,
    failedAlerts []AlertFailure,
    duration time.Duration,
) {
    response := PrometheusAlertsResponse{
        Status: "partial",
        Data: PrometheusAlertsResultData{
            Received:  received,
            Processed: processed,
            Stored:    processed,
            Failed:    len(failedAlerts),
            Errors:    failedAlerts,
            Timestamp: time.Now().Format(time.RFC3339),
        },
    }

    w.Header().Set("Content-Type", "application/json")
    w.WriteHeader(http.StatusMultiStatus) // 207
    json.NewEncoder(w).Encode(response)
}

// respondError sends error response.
func (h *PrometheusAlertsHandler) respondError(
    w http.ResponseWriter,
    statusCode int,
    message string,
    err error,
) {
    errorMsg := message
    if err != nil {
        errorMsg = fmt.Sprintf("%s: %v", message, err)
    }

    response := PrometheusAlertsErrorResponse{
        Status: "error",
        Error:  errorMsg,
    }

    w.Header().Set("Content-Type", "application/json")
    w.WriteHeader(statusCode)
    json.NewEncoder(w).Encode(response)

    h.logger.Error("Request failed", "status", statusCode, "error", errorMsg)
}

// respondValidationError sends 400 Bad Request with validation errors.
func (h *PrometheusAlertsHandler) respondValidationError(
    w http.ResponseWriter,
    validationResult *webhook.ValidationResult,
) {
    errors := make([]ValidationError, len(validationResult.Errors))
    for i, err := range validationResult.Errors {
        errors[i] = ValidationError{
            Field:   err.Field,
            Message: err.Message,
            Value:   err.Value,
        }
    }

    response := PrometheusAlertsErrorResponse{
        Status: "error",
        Error:  "validation failed",
        Errors: errors,
    }

    w.Header().Set("Content-Type", "application/json")
    w.WriteHeader(http.StatusBadRequest)
    json.NewEncoder(w).Encode(response)
}
```

---

### 3. Metrics Collector

**Location**: `go-app/cmd/server/handlers/prometheus_alerts_metrics.go`

**Metrics Definition**:
```go
package handlers

import (
    "time"

    "github.com/prometheus/client_golang/prometheus"
    "github.com/prometheus/client_golang/prometheus/promauto"
)

// PrometheusAlertsMetrics tracks metrics for /api/v2/alerts endpoint.
type PrometheusAlertsMetrics struct {
    // HTTP request metrics
    requestsTotal    *prometheus.CounterVec   // Total requests by status
    requestDuration  *prometheus.HistogramVec // Request duration by status

    // Alert processing metrics
    alertsReceived   *prometheus.CounterVec   // Alerts received by format (v1/v2)
    alertsProcessed  *prometheus.CounterVec   // Alerts processed by status

    // Error metrics
    validationErrors *prometheus.CounterVec   // Validation failures by reason
    processingErrors *prometheus.CounterVec   // Processing errors by type

    // Performance metrics
    concurrentReqs   prometheus.Gauge         // Current concurrent requests
    payloadSize      prometheus.Histogram     // Request payload size
}

// NewPrometheusAlertsMetrics initializes metrics for the endpoint.
func NewPrometheusAlertsMetrics() *PrometheusAlertsMetrics {
    return &PrometheusAlertsMetrics{
        requestsTotal: promauto.NewCounterVec(
            prometheus.CounterOpts{
                Name: "alert_history_prometheus_alerts_requests_total",
                Help: "Total HTTP requests to /api/v2/alerts endpoint",
            },
            []string{"status"}, // success, partial, error
        ),

        requestDuration: promauto.NewHistogramVec(
            prometheus.HistogramOpts{
                Name:    "alert_history_prometheus_alerts_duration_seconds",
                Help:    "Request processing duration for /api/v2/alerts",
                Buckets: []float64{0.001, 0.002, 0.005, 0.01, 0.02, 0.05, 0.1, 0.2, 0.5, 1.0},
            },
            []string{"status"},
        ),

        alertsReceived: promauto.NewCounterVec(
            prometheus.CounterOpts{
                Name: "alert_history_prometheus_alerts_received_total",
                Help: "Total alerts received by format",
            },
            []string{"format"}, // v1, v2
        ),

        alertsProcessed: promauto.NewCounterVec(
            prometheus.CounterOpts{
                Name: "alert_history_prometheus_alerts_processed_total",
                Help: "Total alerts processed by status",
            },
            []string{"status"}, // success, failed
        ),

        validationErrors: promauto.NewCounterVec(
            prometheus.CounterOpts{
                Name: "alert_history_prometheus_alerts_validation_errors_total",
                Help: "Total validation errors by reason",
            },
            []string{"reason"}, // parse_error, validation_error, etc.
        ),

        processingErrors: promauto.NewCounterVec(
            prometheus.CounterOpts{
                Name: "alert_history_prometheus_alerts_processing_errors_total",
                Help: "Total processing errors by type",
            },
            []string{"type"}, // storage_error, processor_error, etc.
        ),

        concurrentReqs: promauto.NewGauge(
            prometheus.GaugeOpts{
                Name: "alert_history_prometheus_alerts_concurrent_requests",
                Help: "Current number of concurrent requests to /api/v2/alerts",
            },
        ),

        payloadSize: promauto.NewHistogram(
            prometheus.HistogramOpts{
                Name:    "alert_history_prometheus_alerts_payload_bytes",
                Help:    "Size of request payload in bytes",
                Buckets: prometheus.ExponentialBuckets(100, 2, 15), // 100B to 1.6MB
            },
        ),
    }
}

// RecordRequest records request metrics.
func (m *PrometheusAlertsMetrics) RecordRequest(status string, alertCount int, duration time.Duration) {
    if m == nil {
        return
    }

    m.requestsTotal.WithLabelValues(status).Inc()
    m.requestDuration.WithLabelValues(status).Observe(duration.Seconds())
}

// RecordAlerts records alert processing metrics.
func (m *PrometheusAlertsMetrics) RecordAlerts(format string, received, processed, failed int) {
    if m == nil {
        return
    }

    m.alertsReceived.WithLabelValues(format).Add(float64(received))
    m.alertsProcessed.WithLabelValues("success").Add(float64(processed))
    if failed > 0 {
        m.alertsProcessed.WithLabelValues("failed").Add(float64(failed))
    }
}

// RecordValidationError records validation error.
func (m *PrometheusAlertsMetrics) RecordValidationError(reason string) {
    if m == nil {
        return
    }
    m.validationErrors.WithLabelValues(reason).Inc()
}

// RecordProcessingError records processing error.
func (m *PrometheusAlertsMetrics) RecordProcessingError(errorType string) {
    if m == nil {
        return
    }
    m.processingErrors.WithLabelValues(errorType).Inc()
}

// RecordPayloadSize records request payload size.
func (m *PrometheusAlertsMetrics) RecordPayloadSize(bytes int) {
    if m == nil {
        return
    }
    m.payloadSize.Observe(float64(bytes))
}

// IncrementConcurrent increments concurrent requests counter.
func (m *PrometheusAlertsMetrics) IncrementConcurrent() {
    if m == nil {
        return
    }
    m.concurrentReqs.Inc()
}

// DecrementConcurrent decrements concurrent requests counter.
func (m *PrometheusAlertsMetrics) DecrementConcurrent() {
    if m == nil {
        return
    }
    m.concurrentReqs.Dec()
}
```

**Helper Method in Handler**:
```go
// recordMetrics records all metrics for a request.
func (h *PrometheusAlertsHandler) recordMetrics(
    status, reason string,
    alertCount int,
    duration time.Duration,
) {
    if h.metrics == nil {
        return
    }

    // Record request metrics
    h.metrics.RecordRequest(status, alertCount, duration)

    // Record validation errors if applicable
    if status == "validation_failed" {
        h.metrics.RecordValidationError(reason)
    }
}
```

---

## Data Flow

### Successful Request Flow (200 OK)

```
1. HTTP POST /api/v2/alerts
   Content-Type: application/json
   Body: [{"labels":{"alertname":"Test"},"state":"firing",...}]

2. PrometheusAlertsHandler.HandlePrometheusAlerts()
   â”œâ”€ Validate method (POST) âœ…
   â”œâ”€ Read body (< 10 MB) âœ…
   â”œâ”€ Parse via TN-146 PrometheusParser âœ…
   â”œâ”€ Validate structure âœ…
   â”œâ”€ Convert to []core.Alert âœ…
   â””â”€ Process alerts sequentially:
       For each alert:
         â”œâ”€ AlertProcessor.ProcessAlert(ctx, alert)
         â”‚   â”œâ”€ Deduplication (TN-036)
         â”‚   â”œâ”€ Inhibition (TN-130)
         â”‚   â”œâ”€ Enrichment (TN-033, optional)
         â”‚   â”œâ”€ Filtering (TN-035, optional)
         â”‚   â”œâ”€ Storage (TN-032)
         â”‚   â””â”€ Publishing (TN-051-060, optional)
         â””â”€ Result: success âœ…

3. Build Response
   â”œâ”€ All alerts processed successfully
   â”œâ”€ Status: 200 OK
   â””â”€ Body: {"status":"success","data":{"received":1,"processed":1,...}}

4. Record Metrics
   â”œâ”€ alert_history_prometheus_alerts_requests_total{status="success"} +1
   â”œâ”€ alert_history_prometheus_alerts_duration_seconds{status="success"} observe(0.003s)
   â”œâ”€ alert_history_prometheus_alerts_received_total{format="v1"} +1
   â””â”€ alert_history_prometheus_alerts_processed_total{status="success"} +1

5. Log Result
   INFO: "Request processing complete" received=1 processed=1 duration_ms=3
```

### Partial Success Flow (207 Multi-Status)

```
1. HTTP POST /api/v2/alerts (5 alerts)

2. PrometheusAlertsHandler.HandlePrometheusAlerts()
   â””â”€ Process alerts:
       Alert 0: âœ… Success
       Alert 1: âŒ Failed (storage timeout)
       Alert 2: âœ… Success
       Alert 3: âŒ Failed (processor error)
       Alert 4: âœ… Success

3. Build Response
   â”œâ”€ Partial success (3/5 processed)
   â”œâ”€ Status: 207 Multi-Status
   â””â”€ Body: {
         "status": "partial",
         "data": {
           "received": 5,
           "processed": 3,
           "failed": 2,
           "errors": [
             {"index": 1, "fingerprint": "abc", "error": "storage timeout"},
             {"index": 3, "fingerprint": "def", "error": "processor error"}
           ]
         }
       }

4. Record Metrics
   â”œâ”€ alert_history_prometheus_alerts_requests_total{status="partial"} +1
   â”œâ”€ alert_history_prometheus_alerts_processed_total{status="success"} +3
   â”œâ”€ alert_history_prometheus_alerts_processed_total{status="failed"} +2
   â””â”€ alert_history_prometheus_alerts_processing_errors_total{type="storage_error"} +1
```

### Validation Error Flow (400 Bad Request)

```
1. HTTP POST /api/v2/alerts
   Body: [{"labels":{},"state":"firing"}] // Missing "alertname"

2. PrometheusAlertsHandler.HandlePrometheusAlerts()
   â”œâ”€ Parse âœ…
   â”œâ”€ Validate âŒ FAILED
   â”‚   â””â”€ Error: "alerts[0].labels.alertname: required field missing"
   â””â”€ Stop processing

3. Build Response
   â”œâ”€ Status: 400 Bad Request
   â””â”€ Body: {
         "status": "error",
         "error": "validation failed",
         "errors": [
           {
             "field": "alerts[0].labels.alertname",
             "message": "required field missing",
             "value": null
           }
         ]
       }

4. Record Metrics
   â”œâ”€ alert_history_prometheus_alerts_requests_total{status="error"} +1
   â””â”€ alert_history_prometheus_alerts_validation_errors_total{reason="validation_error"} +1
```

---

## Interface Specifications

### AlertProcessor Interface (Dependency)

**Location**: `go-app/internal/core/services/alert_processor.go` (already exists)

```go
// AlertProcessor processes alerts through the full pipeline.
type AlertProcessor interface {
    // ProcessAlert processes a single alert through:
    //   - Deduplication (TN-036)
    //   - Inhibition (TN-130)
    //   - Enrichment (TN-033/034, optional)
    //   - Filtering (TN-035, optional)
    //   - Storage (TN-032)
    //   - Publishing (TN-051-060, optional)
    //
    // Returns:
    //   - error: Processing error (if any)
    ProcessAlert(ctx context.Context, alert *core.Alert) error

    // Health checks if AlertProcessor is healthy.
    Health(ctx context.Context) error
}
```

**Usage in TN-147**:
```go
// Process alert through pipeline
err := h.processor.ProcessAlert(ctx, alert)
if err != nil {
    // Log and track failure, but continue processing other alerts
    failedAlerts = append(failedAlerts, AlertFailure{...})
    continue
}
```

### WebhookParser Interface (TN-146)

**Location**: `go-app/internal/infrastructure/webhook/parser.go` (already exists)

```go
// WebhookParser parses and validates webhook payloads.
type WebhookParser interface {
    // Parse parses raw JSON bytes into AlertmanagerWebhook.
    Parse(data []byte) (*AlertmanagerWebhook, error)

    // Validate validates parsed webhook structure.
    Validate(webhook *AlertmanagerWebhook) *ValidationResult

    // ConvertToDomain converts webhook alerts to core.Alert domain models.
    ConvertToDomain(webhook *AlertmanagerWebhook) ([]*core.Alert, error)
}
```

**Usage in TN-147**:
```go
// Parse Prometheus alerts (v1 or v2 format)
webhook, err := h.parser.Parse(body)
if err != nil {
    return // 400 Bad Request
}

// Validate structure
validationResult := h.parser.Validate(webhook)
if !validationResult.Valid {
    return // 400 Bad Request with details
}

// Convert to domain models
alerts, err := h.parser.ConvertToDomain(webhook)
if err != nil {
    return // 422 Unprocessable Entity
}
```

---

## Error Handling Strategy

### Error Classification

| Error Type | HTTP Status | Response Action | Processing Action |
|------------|-------------|-----------------|-------------------|
| **Method Not Allowed** | 405 | Return error response | Stop |
| **Request Too Large** | 413 | Return error response | Stop |
| **Empty Body** | 400 | Return error response | Stop |
| **Malformed JSON** | 400 | Return error response | Stop |
| **Validation Failed** | 400 | Return validation errors | Stop |
| **Conversion Error** | 422 | Return error response | Stop |
| **Too Many Alerts** | 413 | Return error response | Stop |
| **Processing Partial Failure** | 207 | Return partial success | Continue |
| **Processing Complete Failure** | 500 | Return error response | Stop |
| **Processor Unavailable** | 500 | Return error response | Stop |

### Graceful Degradation

```go
// Example: Continue processing on partial failures
for _, alert := range alerts {
    err := h.processor.ProcessAlert(ctx, alert)
    if err != nil {
        // Don't stop processing - log and continue
        h.logger.Warn("Alert processing failed, continuing with next alert",
            "fingerprint", alert.Fingerprint,
            "error", err,
        )
        failedAlerts = append(failedAlerts, AlertFailure{...})
        continue // â† Key: don't return, continue processing
    }
    processedCount++
}

// Return appropriate status
if len(failedAlerts) == 0 {
    return 200 // All success
} else if processedCount > 0 {
    return 207 // Partial success
} else {
    return 500 // All failed
}
```

### Error Logging

```go
// Structured logging with context
h.logger.Error("Alert processing failed",
    "index", i,
    "fingerprint", alert.Fingerprint,
    "alertname", alert.AlertName,
    "error", err,
    "duration_ms", time.Since(startTime).Milliseconds(),
)
```

---

## Performance Optimization

### Target Performance (150% Quality)

| Metric | Baseline (100%) | Target (150%) | Strategy |
|--------|-----------------|---------------|----------|
| **p95 Latency** | < 10ms | < 5ms | Zero-copy parsing, minimal allocations |
| **Throughput** | 1,000 req/s | 2,000+ req/s | Connection pooling, async operations |
| **Memory/req** | < 10 KB | < 5 KB | Buffer reuse, efficient data structures |
| **CPU/req** | < 1ms | < 0.5ms | Optimized hot paths |

### Optimization Techniques

#### 1. Zero-Copy Parsing (where possible)

```go
// Avoid unnecessary copies
body, err := io.ReadAll(r.Body) // â† One allocation
// Pass body directly to parser (no intermediate copies)
webhook, err := h.parser.Parse(body)
```

#### 2. Buffer Pooling

```go
// Use sync.Pool for request body buffers
var bodyBufferPool = sync.Pool{
    New: func() interface{} {
        return new(bytes.Buffer)
    },
}

func (h *PrometheusAlertsHandler) readRequestBody(r *http.Request) ([]byte, error) {
    buf := bodyBufferPool.Get().(*bytes.Buffer)
    defer func() {
        buf.Reset()
        bodyBufferPool.Put(buf)
    }()

    // Read into pooled buffer
    limitedReader := io.LimitReader(r.Body, h.config.MaxRequestSize+1)
    _, err := buf.ReadFrom(limitedReader)
    if err != nil {
        return nil, err
    }

    // Return copy (buffer goes back to pool)
    return append([]byte(nil), buf.Bytes()...), nil
}
```

#### 3. Pre-allocated Slices

```go
// Pre-allocate slices based on expected size
alerts := make([]*core.Alert, 0, len(webhook.Alerts)) // â† Avoid reallocs
failedAlerts := make([]AlertFailure, 0, len(alerts)/10) // Assume 10% failure rate
```

#### 4. Avoid Allocations in Hot Path

```go
// Reuse timestamp instead of creating new ones
now := time.Now()
nowStr := now.Format(time.RFC3339) // â† One allocation
// Use nowStr multiple times in response
```

#### 5. Connection Pooling

**Already handled by dependencies**:
- PostgreSQL: pgxpool (max 25 connections, TN-032)
- Redis: go-redis connection pool (TN-016)
- HTTP client: http.DefaultTransport (TN-051-060)

---

## Observability Design

### Metrics Dashboard (Grafana)

```promql
# Request Rate
rate(alert_history_prometheus_alerts_requests_total[5m])

# p95 Latency
histogram_quantile(0.95,
  rate(alert_history_prometheus_alerts_duration_seconds_bucket[5m])
)

# Success Rate
sum(rate(alert_history_prometheus_alerts_requests_total{status="success"}[5m]))
/ sum(rate(alert_history_prometheus_alerts_requests_total[5m]))

# Alert Processing Rate by Format
rate(alert_history_prometheus_alerts_received_total[5m])

# Error Rate by Reason
sum by (reason) (rate(alert_history_prometheus_alerts_validation_errors_total[5m]))

# Concurrent Requests
alert_history_prometheus_alerts_concurrent_requests
```

### Alerting Rules

```yaml
groups:
  - name: prometheus_alerts_endpoint
    rules:
      # High error rate
      - alert: PrometheusAlertsHighErrorRate
        expr: |
          sum(rate(alert_history_prometheus_alerts_requests_total{status="error"}[5m]))
          / sum(rate(alert_history_prometheus_alerts_requests_total[5m]))
          > 0.05
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High error rate on /api/v2/alerts endpoint"

      # High latency
      - alert: PrometheusAlertsHighLatency
        expr: |
          histogram_quantile(0.95,
            rate(alert_history_prometheus_alerts_duration_seconds_bucket[5m])
          ) > 0.01
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "p95 latency > 10ms on /api/v2/alerts"
```

---

## Testing Strategy

### Unit Tests (25+ tests, 90%+ coverage)

**Location**: `go-app/cmd/server/handlers/prometheus_alerts_test.go`

**Test Categories**:

1. **HTTP Method Tests** (3 tests):
   - `TestHandlePrometheusAlerts_POST_Success`
   - `TestHandlePrometheusAlerts_GET_MethodNotAllowed`
   - `TestHandlePrometheusAlerts_PUT_MethodNotAllowed`

2. **Request Body Tests** (5 tests):
   - `TestHandlePrometheusAlerts_EmptyBody_BadRequest`
   - `TestHandlePrometheusAlerts_TooLargeBody_PayloadTooLarge`
   - `TestHandlePrometheusAlerts_MalformedJSON_BadRequest`
   - `TestHandlePrometheusAlerts_ValidJSON_Success`
   - `TestHandlePrometheusAlerts_TooManyAlerts_EntityTooLarge`

3. **Parsing Tests** (4 tests):
   - `TestHandlePrometheusAlerts_PrometheusV1_Success`
   - `TestHandlePrometheusAlerts_PrometheusV2_Success`
   - `TestHandlePrometheusAlerts_ParseError_BadRequest`
   - `TestHandlePrometheusAlerts_ValidationError_BadRequest`

4. **Processing Tests** (6 tests):
   - `TestHandlePrometheusAlerts_AllAlertsSuccess_200OK`
   - `TestHandlePrometheusAlerts_PartialSuccess_207MultiStatus`
   - `TestHandlePrometheusAlerts_AllFailed_500InternalError`
   - `TestHandlePrometheusAlerts_ProcessorUnavailable_500`
   - `TestHandlePrometheusAlerts_ContextCancellation_Timeout`
   - `TestHandlePrometheusAlerts_ProcessorError_Handling`

5. **Response Tests** (3 tests):
   - `TestHandlePrometheusAlerts_ResponseFormat_Success`
   - `TestHandlePrometheusAlerts_ResponseFormat_Partial`
   - `TestHandlePrometheusAlerts_ResponseFormat_Error`

6. **Metrics Tests** (4 tests):
   - `TestHandlePrometheusAlerts_Metrics_Recorded`
   - `TestHandlePrometheusAlerts_Metrics_Success`
   - `TestHandlePrometheusAlerts_Metrics_Partial`
   - `TestHandlePrometheusAlerts_Metrics_Error`

**Mock Strategy**:
```go
// Mock AlertProcessor
type mockAlertProcessor struct {
    processFunc func(context.Context, *core.Alert) error
    healthFunc  func(context.Context) error
}

func (m *mockAlertProcessor) ProcessAlert(ctx context.Context, alert *core.Alert) error {
    if m.processFunc != nil {
        return m.processFunc(ctx, alert)
    }
    return nil
}

func (m *mockAlertProcessor) Health(ctx context.Context) error {
    if m.healthFunc != nil {
        return m.healthFunc(ctx)
    }
    return nil
}
```

### Integration Tests (5+ tests)

**Location**: `go-app/cmd/server/handlers/prometheus_alerts_integration_test.go`

**Test Categories**:

1. **End-to-End Tests** (3 tests):
   - `TestIntegration_PrometheusAlerts_FullPipeline`
   - `TestIntegration_PrometheusAlerts_WithRealDatabase`
   - `TestIntegration_PrometheusAlerts_MultipleFormats`

2. **Load Tests** (2 tests):
   - `TestIntegration_PrometheusAlerts_ConcurrentRequests`
   - `TestIntegration_PrometheusAlerts_HighThroughput`

### Benchmarks (6+ benchmarks)

**Location**: `go-app/cmd/server/handlers/prometheus_alerts_bench_test.go`

```go
func BenchmarkHandlePrometheusAlerts_SingleAlert(b *testing.B)
func BenchmarkHandlePrometheusAlerts_100Alerts(b *testing.B)
func BenchmarkHandlePrometheusAlerts_1000Alerts(b *testing.B)
func BenchmarkHandlePrometheusAlerts_PrometheusV1(b *testing.B)
func BenchmarkHandlePrometheusAlerts_PrometheusV2(b *testing.B)
func BenchmarkHandlePrometheusAlerts_Concurrent(b *testing.B)
```

**Target Results (150% quality)**:
```
BenchmarkHandlePrometheusAlerts_SingleAlert-8     200000    5000 ns/op    < 5ms
BenchmarkHandlePrometheusAlerts_100Alerts-8        10000   300000 ns/op   < 300ms
BenchmarkHandlePrometheusAlerts_Concurrent-8       50000    50000 ns/op   < 50ms
```

---

## Integration Points

### Registration in main.go

**Location**: `go-app/cmd/server/main.go`

**Integration Code** (add after line ~900):
```go
// TN-147: Initialize Prometheus Alerts Handler (Alertmanager-compatible endpoint)
var prometheusAlertsHandler *handlers.PrometheusAlertsHandler
if alertProcessor != nil {
    slog.Info("Initializing Prometheus Alerts Handler (TN-147)...")

    // Create Prometheus parser (TN-146)
    prometheusParser := webhook.NewPrometheusParser()

    // Create handler configuration
    prometheusAlertsConfig := handlers.DefaultPrometheusAlertsConfig()
    // Override from app config if available
    prometheusAlertsConfig.MaxRequestSize = int64(cfg.Webhook.MaxRequestSize)
    prometheusAlertsConfig.RequestTimeout = cfg.Webhook.RequestTimeout
    prometheusAlertsConfig.MaxAlertsPerReq = cfg.Webhook.MaxAlertsPerReq

    // Create handler
    var err error
    prometheusAlertsHandler, err = handlers.NewPrometheusAlertsHandler(
        prometheusParser,           // TN-146: Prometheus parser
        alertProcessor,              // TN-061: Alert processor
        appLogger,
        prometheusAlertsConfig,
    )
    if err != nil {
        slog.Error("Failed to create Prometheus Alerts Handler", "error", err)
    } else {
        slog.Info("âœ… Prometheus Alerts Handler initialized (TN-147)",
            "max_request_size", prometheusAlertsConfig.MaxRequestSize,
            "request_timeout", prometheusAlertsConfig.RequestTimeout,
            "max_alerts_per_req", prometheusAlertsConfig.MaxAlertsPerReq,
            "status", "PRODUCTION-READY")
    }
} else {
    slog.Warn("âš ï¸ Prometheus Alerts Handler NOT initialized (AlertProcessor unavailable)")
}

// ... existing code ...

// TN-147: Register Prometheus Alerts endpoint (Alertmanager compatible)
if prometheusAlertsHandler != nil {
    mux.HandleFunc("POST /api/v2/alerts", prometheusAlertsHandler.HandlePrometheusAlerts)
    slog.Info("âœ… POST /api/v2/alerts endpoint registered",
        "handler", "PrometheusAlertsHandler (TN-147)",
        "compatibility", "Alertmanager API v2",
        "formats", "Prometheus v1 (array) + v2 (grouped)",
        "features", []string{
            "Format auto-detection",
            "Comprehensive validation",
            "Best-effort processing",
            "Partial success responses (207)",
            "8 Prometheus metrics",
            "Structured logging",
        })
} else {
    slog.Warn("âš ï¸ POST /api/v2/alerts endpoint NOT available (handler not initialized)")
}
```

### Dependencies Summary

**All dependencies satisfied (0 blockers)**:

| Dependency | Status | Version | Quality |
|------------|--------|---------|---------|
| TN-146 (Prometheus Parser) | âœ… COMPLETE | 159% | Grade A+ |
| TN-043 (Webhook Validator) | âœ… COMPLETE | 150% | Grade A+ |
| TN-061 (AlertProcessor) | âœ… COMPLETE | 150% | Grade A++ |
| TN-036 (Deduplication) | âœ… COMPLETE | 150% | 98.14% coverage |
| TN-032 (Storage) | âœ… COMPLETE | 95% | Production-ready |
| TN-021 (Metrics) | âœ… COMPLETE | - | MetricsRegistry |
| TN-020 (Logging) | âœ… COMPLETE | - | slog stdlib |

---

## Implementation Checklist

### Phase 2: Handler Implementation (This Design)

- [ ] **File Structure**:
  - [ ] Create `go-app/cmd/server/handlers/prometheus_alerts.go`
  - [ ] Create `go-app/cmd/server/handlers/prometheus_alerts_metrics.go`
  - [ ] Create `go-app/cmd/server/handlers/prometheus_alerts_test.go`
  - [ ] Create `go-app/cmd/server/handlers/prometheus_alerts_bench_test.go`

- [ ] **Core Structs**:
  - [ ] `PrometheusAlertsHandler` struct with fields
  - [ ] `PrometheusAlertsConfig` struct
  - [ ] `PrometheusAlertsResponse` struct
  - [ ] `PrometheusAlertsErrorResponse` struct
  - [ ] `AlertFailure` struct

- [ ] **Handler Methods**:
  - [ ] `NewPrometheusAlertsHandler()` constructor
  - [ ] `HandlePrometheusAlerts()` main handler
  - [ ] `readRequestBody()` helper
  - [ ] `processAlerts()` processing loop
  - [ ] `respondSuccess()` response builder
  - [ ] `respondPartialSuccess()` response builder
  - [ ] `respondError()` response builder
  - [ ] `respondValidationError()` response builder
  - [ ] `recordMetrics()` metrics helper

- [ ] **Metrics**:
  - [ ] `PrometheusAlertsMetrics` struct
  - [ ] 8 metrics definitions
  - [ ] Metric recording methods
  - [ ] Integration with Prometheus registry

- [ ] **Integration**:
  - [ ] Add handler initialization in main.go
  - [ ] Register `POST /api/v2/alerts` route
  - [ ] Configuration loading
  - [ ] Logging integration

### Phase 3: Testing (90%+ coverage target)

- [ ] **Unit Tests** (25+ tests):
  - [ ] HTTP method tests (3)
  - [ ] Request body tests (5)
  - [ ] Parsing tests (4)
  - [ ] Processing tests (6)
  - [ ] Response tests (3)
  - [ ] Metrics tests (4)

- [ ] **Integration Tests** (5+ tests):
  - [ ] End-to-end tests (3)
  - [ ] Load tests (2)

- [ ] **Benchmarks** (6+ benchmarks):
  - [ ] Single alert benchmark
  - [ ] 100 alerts benchmark
  - [ ] 1000 alerts benchmark
  - [ ] v1 format benchmark
  - [ ] v2 format benchmark
  - [ ] Concurrent requests benchmark

- [ ] **Quality Checks**:
  - [ ] Run `go test -v -cover` (target: 90%+)
  - [ ] Run `go test -race` (zero race conditions)
  - [ ] Run `golangci-lint run` (zero warnings)
  - [ ] Run benchmarks (verify < 5ms p95)

### Phase 4: Documentation

- [ ] **Code Documentation**:
  - [ ] Godoc comments on all public types
  - [ ] Godoc comments on all public methods
  - [ ] Code examples in comments

- [ ] **External Documentation**:
  - [ ] requirements.md (1,000+ LOC) âœ… DONE
  - [ ] design.md (800+ LOC) â† THIS FILE
  - [ ] tasks.md (600+ LOC)
  - [ ] API_DOCUMENTATION.md (500+ LOC)
  - [ ] CERTIFICATION.md (400+ LOC)

---

## Summary

### Implementation Scope

**What TN-147 Implements** (NEW):
- âœ… PrometheusAlertsHandler HTTP handler
- âœ… Response builders (200/207/400/500)
- âœ… Metrics collector (8 Prometheus metrics)
- âœ… Request orchestration
- âœ… Error handling & graceful degradation
- âœ… Integration with main.go
- âœ… Comprehensive tests (25+ unit, 5+ integration, 6+ benchmarks)

**What TN-147 Reuses** (EXISTING):
- âœ… PrometheusParser (TN-146) for parsing
- âœ… WebhookValidator (TN-043) for validation
- âœ… AlertProcessor (TN-061) for processing pipeline
- âœ… Deduplication (TN-036)
- âœ… Storage (TN-032)
- âœ… All other downstream components

### Estimated LOC

| Component | LOC | File |
|-----------|-----|------|
| **Handler** | 400 | prometheus_alerts.go |
| **Metrics** | 150 | prometheus_alerts_metrics.go |
| **Tests** | 800 | *_test.go files |
| **Benchmarks** | 200 | *_bench_test.go |
| **Documentation** | 3,500+ | requirements, design, tasks, API, cert |
| **Total** | **5,050+** | All files |

### Quality Targets (150%)

- âœ… **Implementation**: 600+ LOC production code
- âœ… **Testing**: 90%+ coverage, 25+ tests, 6+ benchmarks
- âœ… **Performance**: < 5ms p95 latency, 2,000+ req/s throughput
- âœ… **Documentation**: 3,500+ LOC (5 comprehensive documents)
- âœ… **Quality**: Zero linter warnings, zero race conditions
- âœ… **Compatibility**: 100% Alertmanager API v2

### Next Steps

1. âœ… **Phase 0-1**: Requirements + Design COMPLETE
2. ğŸ¯ **Phase 2**: Implementation (handlers + metrics)
3. ğŸ¯ **Phase 3**: Testing (unit + integration + benchmarks)
4. ğŸ¯ **Phase 4**: Documentation (tasks.md + API + certification)
5. ğŸ¯ **Phase 5**: Performance optimization
6. ğŸ¯ **Phase 6**: Final certification (150% quality report)

---

**Document Status**: âœ… COMPLETE
**Total Lines**: 1,250+ LOC
**Quality Target**: 150% (Grade A+ EXCEPTIONAL)
**Last Updated**: 2025-11-18
**Author**: AI Engineering Team
**Ready for**: Implementation (Phase 2)
