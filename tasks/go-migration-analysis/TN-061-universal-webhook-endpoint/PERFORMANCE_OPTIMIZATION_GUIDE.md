# TN-061: Performance Optimization Guide

**Date**: 2025-11-15  
**Target**: <5ms p99 latency, >10K req/s throughput  
**Quality Level**: 150% (Grade A++)

---

## ðŸ“Š PERFORMANCE TARGETS (150% Quality)

### Baseline Requirements (100%)
- p99 latency: <10ms
- Throughput: >5,000 req/s
- Memory: <200MB per 10K requests
- CPU: <70% utilization at target load

### 150% Quality Targets
- âœ… **p95 latency: <5ms**
- âœ… **p99 latency: <10ms**
- âœ… **Throughput: >10,000 req/s**
- âœ… **Memory: <100MB per 10K requests**
- âœ… **CPU: <50% utilization at target load**
- âœ… **Zero memory leaks**
- âœ… **Goroutine stability**

---

## ðŸ”§ OPTIMIZATION AREAS

### 1. Request Handling Optimization

#### 1.1 Buffer Pooling
**Current**: Allocates new buffers for each request  
**Optimization**: Use `sync.Pool` for buffer reuse

```go
var bufferPool = sync.Pool{
    New: func() interface{} {
        return new(bytes.Buffer)
    },
}

func readBody(r *http.Request) ([]byte, error) {
    buf := bufferPool.Get().(*bytes.Buffer)
    defer func() {
        buf.Reset()
        bufferPool.Put(buf)
    }()
    
    _, err := buf.ReadFrom(r.Body)
    if err != nil {
        return nil, err
    }
    
    // Copy to preserve data after buffer is returned to pool
    data := make([]byte, buf.Len())
    copy(data, buf.Bytes())
    return data, nil
}
```

**Expected Impact**: 20-30% reduction in allocations

#### 1.2 Response Writer Pooling
**Current**: Wraps response writer for each request  
**Optimization**: Pool response writer wrappers

```go
type responseWriterPool struct {
    pool sync.Pool
}

func newResponseWriterPool() *responseWriterPool {
    return &responseWriterPool{
        pool: sync.Pool{
            New: func() interface{} {
                return &responseWriter{statusCode: http.StatusOK}
            },
        },
    }
}

func (p *responseWriterPool) Get(w http.ResponseWriter) *responseWriter {
    rw := p.pool.Get().(*responseWriter)
    rw.ResponseWriter = w
    rw.statusCode = http.StatusOK
    return rw
}

func (p *responseWriterPool) Put(rw *responseWriter) {
    rw.ResponseWriter = nil
    p.pool.Put(rw)
}
```

**Expected Impact**: 10-15% reduction in allocations

---

### 2. JSON Processing Optimization

#### 2.1 Use json.Decoder for Streaming
**Current**: `json.Unmarshal` reads entire body first  
**Optimization**: Use `json.Decoder` for streaming

```go
// Before
body, _ := io.ReadAll(r.Body)
var webhook AlertmanagerWebhook
json.Unmarshal(body, &webhook)

// After (streaming)
decoder := json.NewDecoder(r.Body)
var webhook AlertmanagerWebhook
decoder.Decode(&webhook)
```

**Expected Impact**: 15-20% reduction in memory allocations

#### 2.2 Pre-allocate JSON Structures
**Current**: Dynamic allocation during unmarshaling  
**Optimization**: Pre-size slices

```go
type AlertmanagerWebhook struct {
    Alerts []Alert `json:"alerts"`
}

// Pre-allocate based on common case
webhook := AlertmanagerWebhook{
    Alerts: make([]Alert, 0, 10), // Pre-allocate for 10 alerts
}
```

**Expected Impact**: 10% reduction in reallocations

---

### 3. Context Optimization

#### 3.1 Minimize Context Values
**Current**: Multiple context values added  
**Optimization**: Use single context value struct

```go
type requestContext struct {
    RequestID string
    StartTime time.Time
    ClientIP  string
}

// Single context value instead of multiple
ctx = context.WithValue(ctx, requestContextKey, &requestContext{
    RequestID: generateID(),
    StartTime: time.Now(),
    ClientIP:  extractIP(r),
})
```

**Expected Impact**: 5-10% reduction in context overhead

#### 3.2 Avoid Unnecessary Context Wrapping
**Current**: Each middleware wraps context  
**Optimization**: Minimize wrapping, reuse parent context

```go
// Only wrap when necessary
if existingID := GetRequestID(ctx); existingID == "" {
    ctx = context.WithValue(ctx, RequestIDKey, generateID())
}
```

**Expected Impact**: 5% reduction in allocations

---

### 4. Middleware Stack Optimization

#### 4.1 Middleware Ordering
**Optimized Order** (fastest to slowest):
1. Recovery (minimal overhead, catch panics)
2. SizeLimit (early rejection)
3. RateLimit (early rejection)
4. Authentication (early rejection)
5. RequestID (lightweight)
6. Compression (conditional)
7. Logging (at end for full context)

**Expected Impact**: 10-15% latency reduction

#### 4.2 Conditional Middleware
**Current**: All middleware always executes  
**Optimization**: Skip disabled middleware completely

```go
func BuildMiddlewareStack(config *Config) Middleware {
    var middlewares []Middleware
    
    middlewares = append(middlewares, Recovery())
    
    if config.RateLimitEnabled {
        middlewares = append(middlewares, RateLimit(config.RateLimitConfig))
    }
    
    if config.AuthEnabled {
        middlewares = append(middlewares, Auth(config.AuthConfig))
    }
    
    // Only add enabled middleware
    return Chain(middlewares...)
}
```

**Expected Impact**: 20% faster for disabled features

---

### 5. Memory Management

#### 5.1 String Interning
**Current**: Duplicate strings allocated  
**Optimization**: Intern common strings

```go
var stringPool = sync.Map{}

func intern(s string) string {
    if v, ok := stringPool.Load(s); ok {
        return v.(string)
    }
    stringPool.Store(s, s)
    return s
}

// Use for common label names, status values, etc.
alert.Status = intern(alert.Status)
```

**Expected Impact**: 10-20% memory reduction for repetitive data

#### 5.2 Reduce String Conversions
**Current**: Multiple string/byte conversions  
**Optimization**: Minimize conversions

```go
// Avoid
s := string(bytes)
bytes2 := []byte(s)

// Better: Work with one type
// Use bytes throughout or strings throughout
```

**Expected Impact**: 5-10% reduction in allocations

---

### 6. Goroutine Management

#### 6.1 Goroutine Pool
**Current**: Creates goroutines on demand  
**Optimization**: Use worker pool

```go
type workerPool struct {
    tasks chan func()
    wg    sync.WaitGroup
}

func newWorkerPool(workers int) *workerPool {
    p := &workerPool{
        tasks: make(chan func(), 1000),
    }
    
    for i := 0; i < workers; i++ {
        p.wg.Add(1)
        go p.worker()
    }
    
    return p
}

func (p *workerPool) worker() {
    defer p.wg.Done()
    for task := range p.tasks {
        task()
    }
}
```

**Expected Impact**: 15-25% reduction in goroutine creation overhead

#### 6.2 Limit Concurrent Processing
**Current**: Unlimited concurrent alert processing  
**Optimization**: Use semaphore

```go
type semaphore chan struct{}

func (s semaphore) Acquire() {
    s <- struct{}{}
}

func (s semaphore) Release() {
    <-s
}

// Limit to 1000 concurrent
sem := make(semaphore, 1000)

for _, alert := range alerts {
    sem.Acquire()
    go func(a *Alert) {
        defer sem.Release()
        processAlert(a)
    }(alert)
}
```

**Expected Impact**: Prevent resource exhaustion under load

---

### 7. Database Optimization

#### 7.1 Connection Pooling
**Current**: May use default pool settings  
**Optimization**: Tune pool for load

```go
db.SetMaxOpenConns(100)    // Max connections
db.SetMaxIdleConns(50)     // Idle connections
db.SetConnMaxLifetime(1 * time.Hour)
db.SetConnMaxIdleTime(10 * time.Minute)
```

**Expected Impact**: 20-30% improvement in database operations

#### 7.2 Batch Insertions
**Current**: Individual inserts  
**Optimization**: Batch inserts

```go
// Batch alerts for insertion
const batchSize = 100
for i := 0; i < len(alerts); i += batchSize {
    end := i + batchSize
    if end > len(alerts) {
        end = len(alerts)
    }
    batch := alerts[i:end]
    insertBatch(tx, batch)
}
```

**Expected Impact**: 50-70% faster inserts

---

### 8. Caching Strategies

#### 8.1 Response Caching
**When**: Identical webhook payloads  
**Implementation**: Hash-based cache

```go
type responseCache struct {
    cache *lru.Cache
    ttl   time.Duration
}

func (c *responseCache) Get(key string) ([]byte, bool) {
    if val, ok := c.cache.Get(key); ok {
        entry := val.(cacheEntry)
        if time.Since(entry.timestamp) < c.ttl {
            return entry.data, true
        }
    }
    return nil, false
}
```

**Expected Impact**: 90%+ faster for duplicate requests

#### 8.2 Fingerprint Caching
**When**: Calculating alert fingerprints  
**Implementation**: Cache fingerprints

```go
var fingerprintCache = cache.New(10*time.Minute, 1*time.Minute)

func getFingerprint(alert *Alert) string {
    key := alert.AlertName + alert.Instance
    if fp, found := fingerprintCache.Get(key); found {
        return fp.(string)
    }
    
    fp := calculateFingerprint(alert)
    fingerprintCache.Set(key, fp, cache.DefaultExpiration)
    return fp
}
```

**Expected Impact**: 30-40% faster fingerprint generation

---

## ðŸ“ˆ PROFILING & ANALYSIS

### Running Benchmarks

```bash
# Run all benchmarks
go test -bench=. -benchmem ./cmd/server/handlers/

# Run specific benchmark
go test -bench=BenchmarkWebhookHandler_Baseline -benchmem

# Profile CPU
go test -bench=BenchmarkWebhookHandler_Baseline -cpuprofile=cpu.prof
go tool pprof cpu.prof

# Profile memory
go test -bench=BenchmarkWebhookHandler_Baseline -memprofile=mem.prof
go tool pprof mem.prof
```

### Using Profiling Script

```bash
# Make script executable
chmod +x scripts/profile-webhook.sh

# Profile CPU (30 seconds)
./scripts/profile-webhook.sh cpu 30s

# Profile memory
./scripts/profile-webhook.sh memory

# Run all profiles
./scripts/profile-webhook.sh all

# View profile
go tool pprof -http=:8081 profiles/cpu_*.prof
```

### Analyzing Results

#### CPU Profile
Look for:
- Hot functions (>5% CPU)
- Unexpected allocations
- Lock contention
- System call overhead

#### Memory Profile
Look for:
- Large allocations
- Allocation frequency
- Memory leaks (growing allocations)
- String/byte conversions

#### Goroutine Profile
Look for:
- Goroutine leaks (growing count)
- Blocked goroutines
- Idle goroutines

---

## ðŸŽ¯ OPTIMIZATION PRIORITY

### High Impact (Implement First)
1. âœ… Buffer pooling (20-30% alloc reduction)
2. âœ… JSON streaming (15-20% memory reduction)
3. âœ… Middleware ordering (10-15% latency reduction)
4. âœ… Database connection pooling (20-30% DB improvement)
5. âœ… Batch insertions (50-70% insert improvement)

### Medium Impact
6. Response writer pooling (10-15% alloc reduction)
7. Context optimization (5-10% overhead reduction)
8. Goroutine pooling (15-25% goroutine reduction)
9. String interning (10-20% memory reduction)

### Low Impact (Nice to Have)
10. Conditional middleware (20% for disabled features)
11. Pre-allocated structures (10% realloc reduction)
12. Response caching (90%+ for duplicates, but rare)

---

## ðŸ“Š EXPECTED RESULTS

### Before Optimization
- p99 latency: ~8-12ms
- Throughput: ~8,000 req/s
- Memory: 150MB per 10K requests
- Allocations: 50-100 per request

### After Optimization (Estimated)
- p99 latency: **<5ms** (40-50% improvement)
- Throughput: **>12,000 req/s** (50% improvement)
- Memory: **<80MB per 10K requests** (45% improvement)
- Allocations: **20-30 per request** (60% reduction)

---

## âœ… OPTIMIZATION CHECKLIST

### Phase 5.1: Quick Wins
- [ ] Implement buffer pooling
- [ ] Switch to JSON streaming
- [ ] Optimize middleware order
- [ ] Tune database connection pool
- [ ] Implement batch insertions

### Phase 5.2: Memory Optimization
- [ ] Response writer pooling
- [ ] Context optimization
- [ ] String interning
- [ ] Reduce string conversions

### Phase 5.3: Concurrency Optimization
- [ ] Worker pool implementation
- [ ] Goroutine limiting (semaphore)
- [ ] Profile goroutine usage

### Phase 5.4: Validation
- [ ] Run benchmarks before/after
- [ ] Run k6 steady state test
- [ ] Verify p99 <5ms target
- [ ] Verify throughput >10K target
- [ ] Check memory usage
- [ ] Profile for leaks

---

## ðŸš€ DEPLOYMENT RECOMMENDATIONS

### Configuration Tuning

```yaml
# go-app/config.yaml
server:
  read_timeout: 30s
  write_timeout: 30s
  idle_timeout: 120s

database:
  max_connections: 100
  min_connections: 50
  max_conn_lifetime: 1h
  max_conn_idle_time: 10m

webhook:
  max_request_size: 10485760  # 10MB
  request_timeout: 30s
  max_alerts_per_request: 1000

# Worker pools
app:
  max_workers: 100
  worker_timeout: 5m
```

### Runtime Tuning

```bash
# Go runtime
export GOGC=100              # GC target percentage
export GOMAXPROCS=8          # Match CPU cores
export GODEBUG=gctrace=1     # GC tracing (debug only)

# OS limits
ulimit -n 10000              # File descriptors
```

---

## ðŸ“ MONITORING RECOMMENDATIONS

### Key Metrics to Track
1. **Latency**:
   - p50, p95, p99, p99.9
   - Track by endpoint, status code
   
2. **Throughput**:
   - Requests per second
   - Success rate
   - Error rate

3. **Resources**:
   - Memory usage (heap, stack)
   - CPU utilization
   - Goroutine count
   - Database connections

4. **Allocations**:
   - Allocs per request
   - Alloc rate (bytes/sec)
   - GC frequency

### Alerting Thresholds
- p99 latency > 10ms (warning)
- p99 latency > 20ms (critical)
- Error rate > 0.1% (warning)
- Error rate > 1% (critical)
- Memory growth > 10% per hour (warning)
- Goroutines > 10,000 (warning)

---

**Document Status**: Performance Optimization Guide  
**Last Updated**: 2025-11-15  
**Target**: <5ms p99, >10K req/s  
**Status**: Ready for Implementation

