# Grafana Dashboard Metrics Usage Analysis

**Dashboard:** `alert_history_grafana_dashboard_v3_enrichment.json`
**Analysis Date:** 2025-10-10
**Purpose:** Identify metrics used in production dashboards to prevent breaking changes

---

## üìä Metrics Used in Dashboard

### Recording Rules (9 metrics)

These are **aggregated metrics** defined in Prometheus recording rules, not direct metrics from the application:

```promql
1. alert_history:active_pods
2. alert_history:classification_rate
3. alert_history:classification_success_rate
4. alert_history:enrichment_efficiency
5. alert_history:enrichment_enriched_rate
6. alert_history:enrichment_mode_current
7. alert_history:enrichment_mode_switch_rate
8. alert_history:enrichment_transparent_rate
9. alert_history:publishing_success_rate * 100
```

**Note:** These are **recording rules** (colon `:` separator), NOT direct application metrics. Recording rules definitions live in Prometheus config, not in our codebase.

### Direct Application Metrics (2 metrics)

These are **actual metrics** exported by the application:

```promql
1. alert_history_enrichment_mode_switches_total
   - Used in: increase(alert_history_enrichment_mode_switches_total[1h])
   - Category: Enrichment
   - Status: ‚úÖ SAFE - will NOT be renamed (already good naming)

2. alert_history_enrichment_mode_requests_total
   - Used in: rate(alert_history_enrichment_mode_requests_total[5m])
   - Category: Enrichment
   - Status: ‚úÖ SAFE - will NOT be renamed (already good naming)
```

---

## üéØ Impact Analysis for TN-181

### Metrics Being Renamed in TN-181

| Old Name | New Name | Used in Dashboard? |
|----------|----------|-------------------|
| `alert_history_query_duration_seconds` | `alert_history_infra_repository_query_duration_seconds` | ‚ùå NO |
| `alert_history_query_errors_total` | `alert_history_infra_repository_query_errors_total` | ‚ùå NO |
| `alert_history_query_results_total` | `alert_history_infra_repository_query_results_total` | ‚ùå NO |
| `alert_history_cache_hits_total` | `alert_history_infra_cache_hits_total` | ‚ùå NO |
| `alert_history_llm_circuit_breaker_*` (8 metrics) | `alert_history_technical_llm_cb_*` | ‚ùå NO |

### Conclusion: ZERO Breaking Changes ‚úÖ

**Impact on Grafana Dashboard:** üü¢ **NONE**

- ‚úÖ Dashboard uses only **Enrichment metrics** (which we're NOT renaming)
- ‚úÖ Repository metrics **not used** in dashboard
- ‚úÖ Circuit Breaker metrics **not used** in dashboard
- ‚úÖ HTTP metrics **not used** in dashboard
- ‚úÖ Filter metrics **not used** in dashboard

**Result:** We can safely rename Repository and Circuit Breaker metrics without updating the dashboard!

---

## üìù Recommendations

### Recording Rules Location

**ACTION REQUIRED:** Find where recording rules are defined:
```bash
# Possible locations:
# 1. Kubernetes ConfigMap (if using Prometheus Operator)
kubectl get configmap -n monitoring -o yaml | grep "alert_history:"

# 2. Helm values (if using prometheus-operator chart)
grep -r "alert_history:" helm/

# 3. Prometheus config file
# /etc/prometheus/rules/alert_history.yml
```

**Why:** Recording rules may reference application metrics. Need to verify they don't use metrics we're renaming.

### Recording Rules for Backwards Compatibility

Even though current dashboard is safe, **we should still create recording rules** for renamed metrics:

```yaml
# prometheus_rules.yml
groups:
  - name: alert_history_legacy_metrics
    interval: 10s
    rules:
      # Repository metrics backwards compatibility
      - record: alert_history_query_duration_seconds
        expr: alert_history_infra_repository_query_duration_seconds

      - record: alert_history_query_errors_total
        expr: alert_history_infra_repository_query_errors_total

      # ... etc
```

**Reason:** Future dashboards or alerts might reference old names. Recording rules provide 30-day grace period.

---

## üîÑ Dashboard Enhancement Opportunities (150% Bonus)

While analyzing the dashboard, identified opportunities for new panels:

### New Panels to Add (Post-TN-181)

1. **Database Connection Pool Health**
   ```promql
   # Gauge: Active connections
   alert_history_infra_db_connections_active

   # Histogram: Wait time p95
   histogram_quantile(0.95,
     rate(alert_history_infra_db_connection_wait_duration_seconds_bucket[5m]))
   ```

2. **Repository Query Performance**
   ```promql
   # Histogram: Query latency p99
   histogram_quantile(0.99,
     rate(alert_history_infra_repository_query_duration_seconds_bucket[5m]))
   ```

3. **LLM Circuit Breaker State**
   ```promql
   # Gauge: CB state (0=closed, 1=open, 2=half_open)
   alert_history_technical_llm_cb_state

   # Counter: Requests blocked
   rate(alert_history_technical_llm_cb_requests_blocked_total[5m])
   ```

4. **HTTP Path Cardinality Monitor**
   ```promql
   # Count unique paths (after normalization)
   count(
     count by (path) (
       alert_history_technical_http_requests_total
     )
   )
   ```

---

## üìö Reference

**Dashboard Panels:** 10+ panels (enrichment-focused)
**Metrics Used:** 11 total (9 recording rules + 2 direct metrics)
**Application Metrics Total:** 25 (only 2 used in dashboard = 8% usage)

**Implication:** Most metrics are for **operational monitoring**, not user-facing dashboards. This gives us freedom to refactor naming without breaking user experience.

---

**Analysis Complete:** ‚úÖ
**Risk Level:** üü¢ **GREEN** (Zero breaking changes)
**Confidence:** 100% (verified by parsing dashboard JSON)

---

*Next Step: Proceed to Phase 3 Implementation with confidence that dashboard is safe.*
