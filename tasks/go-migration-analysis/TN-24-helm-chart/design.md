# TN-24: –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ Helm Chart –¥–ª—è alert-history-go

## üèóÔ∏è **–ê–†–•–ò–¢–ï–ö–¢–£–†–ù–´–ô –û–ë–ó–û–†**

### **–¶–µ–ª—å –∏ –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ**

Helm chart —è–≤–ª—è–µ—Ç—Å—è –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –≤–∞–∂–Ω—ã–º –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–º –¥–ª—è production deployment Go –≤–µ—Ä—Å–∏–∏ Alert History Service. –û–Ω –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç:

- **–ê–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ** –≤—Å–µ—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
- **–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–æ–Ω–Ω–æ–µ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ** –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Å—Ä–µ–¥
- **–ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º–æ—Å—Ç—å** –∏ –≤—ã—Å–æ–∫—É—é –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å
- **–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥** –∏ –Ω–∞–±–ª—é–¥–∞–µ–º–æ—Å—Ç—å
- **–ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å** –Ω–∞ —É—Ä–æ–≤–Ω–µ –∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä—ã

## üìã **–ê–†–•–ò–¢–ï–ö–¢–£–†–ê HELM CHART**

### **–û–±—â–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—è**

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                        Kubernetes Cluster                           ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ                    Ingress Controller                          ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ                    alert-history-go                         ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îÇ ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îÇ  ‚îÇ  Deployment ‚îÇ  ‚îÇ   Service   ‚îÇ  ‚îÇ  ConfigMap  ‚îÇ     ‚îÇ ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îÇ  ‚îÇ             ‚îÇ  ‚îÇ             ‚îÇ  ‚îÇ             ‚îÇ     ‚îÇ ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îÇ  ‚îÇ ‚Ä¢ 3 replicas‚îÇ  ‚îÇ ‚Ä¢ ClusterIP ‚îÇ  ‚îÇ ‚Ä¢ App config‚îÇ     ‚îÇ ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îÇ  ‚îÇ ‚Ä¢ Resources ‚îÇ  ‚îÇ ‚Ä¢ Port 8080 ‚îÇ  ‚îÇ ‚Ä¢ Env vars   ‚îÇ     ‚îÇ ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îÇ  ‚îÇ ‚Ä¢ Probes    ‚îÇ  ‚îÇ             ‚îÇ  ‚îÇ             ‚îÇ     ‚îÇ ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îÇ ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ                                                                     ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ                      PostgreSQL StatefulSet                     ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îÇ ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îÇ StatefulSet ‚îÇ  ‚îÇ   Service   ‚îÇ  ‚îÇ     PVC     ‚îÇ         ‚îÇ ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îÇ             ‚îÇ  ‚îÇ             ‚îÇ  ‚îÇ             ‚îÇ         ‚îÇ ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îÇ ‚Ä¢ 1 replica ‚îÇ  ‚îÇ ‚Ä¢ ClusterIP ‚îÇ  ‚îÇ ‚Ä¢ 10Gi SSD  ‚îÇ         ‚îÇ ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îÇ ‚Ä¢ PVC       ‚îÇ  ‚îÇ ‚Ä¢ Port 5432 ‚îÇ  ‚îÇ ‚Ä¢ Retention ‚îÇ         ‚îÇ ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îÇ ‚Ä¢ Init      ‚îÇ  ‚îÇ             ‚îÇ  ‚îÇ             ‚îÇ         ‚îÇ ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îÇ ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ                                                                     ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ                        Redis Deployment                        ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îÇ ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îÇ Deployment  ‚îÇ  ‚îÇ   Service   ‚îÇ  ‚îÇ     PVC     ‚îÇ         ‚îÇ ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îÇ             ‚îÇ  ‚îÇ             ‚îÇ  ‚îÇ             ‚îÇ         ‚îÇ ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îÇ ‚Ä¢ 1 replica ‚îÇ  ‚îÇ ‚Ä¢ ClusterIP ‚îÇ  ‚îÇ ‚Ä¢ 1Gi SSD   ‚îÇ         ‚îÇ ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îÇ ‚Ä¢ PVC       ‚îÇ  ‚îÇ ‚Ä¢ Port 6379 ‚îÇ  ‚îÇ ‚Ä¢ Snapshots ‚îÇ         ‚îÇ ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îÇ ‚Ä¢ Auth      ‚îÇ  ‚îÇ             ‚îÇ  ‚îÇ             ‚îÇ         ‚îÇ ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îÇ ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ                                                                     ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ                     Monitoring Stack                           ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îÇ ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îÇServiceMonitor‚îÇ  ‚îÇPodMonitor ‚îÇ  ‚îÇPrometheus   ‚îÇ         ‚îÇ ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îÇ             ‚îÇ  ‚îÇ            ‚îÇ  ‚îÇRules        ‚îÇ         ‚îÇ ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îÇ ‚Ä¢ App metrics‚îÇ  ‚îÇ ‚Ä¢ Container‚îÇ  ‚îÇ ‚Ä¢ Alerts    ‚îÇ         ‚îÇ ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îÇ ‚Ä¢ Endpoints ‚îÇ  ‚îÇ  metrics   ‚îÇ  ‚îÇ ‚Ä¢ SLOs      ‚îÇ         ‚îÇ ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îÇ ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## üîß **–°–¢–†–£–ö–¢–£–†–ê HELM CHART**

### **–ö–æ—Ä–Ω–µ–≤–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞**

```
alert-history-go/
‚îú‚îÄ‚îÄ Chart.yaml                 # –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ —á–∞—Ä—Ç–∞
‚îú‚îÄ‚îÄ values.yaml               # –ó–Ω–∞—á–µ–Ω–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
‚îú‚îÄ‚îÄ values-dev.yaml          # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–ª—è development
‚îú‚îÄ‚îÄ values-staging.yaml      # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–ª—è staging
‚îú‚îÄ‚îÄ values-prod.yaml         # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–ª—è production
‚îú‚îÄ‚îÄ templates/
‚îÇ   ‚îú‚îÄ‚îÄ _helpers.tpl         # Helper —Ñ—É–Ω–∫—Ü–∏–∏
‚îÇ   ‚îú‚îÄ‚îÄ deployment.yaml      # Deployment –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
‚îÇ   ‚îú‚îÄ‚îÄ service.yaml         # Service –¥–ª—è –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
‚îÇ   ‚îú‚îÄ‚îÄ ingress.yaml         # Ingress –ø—Ä–∞–≤–∏–ª–∞
‚îÇ   ‚îú‚îÄ‚îÄ configmap.yaml       # ConfigMap –¥–ª—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
‚îÇ   ‚îú‚îÄ‚îÄ secret.yaml          # Secret –¥–ª—è —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
‚îÇ   ‚îú‚îÄ‚îÄ hpa.yaml            # HorizontalPodAutoscaler
‚îÇ   ‚îú‚îÄ‚îÄ pdb.yaml            # PodDisruptionBudget
‚îÇ   ‚îú‚îÄ‚îÄ networkpolicy.yaml  # NetworkPolicy
‚îÇ   ‚îú‚îÄ‚îÄ postgresql/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ statefulset.yaml # PostgreSQL StatefulSet
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ service.yaml     # PostgreSQL Service
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ pvc.yaml         # PersistentVolumeClaim
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ secret.yaml      # PostgreSQL credentials
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ configmap.yaml   # PostgreSQL configuration
‚îÇ   ‚îú‚îÄ‚îÄ redis/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ deployment.yaml  # Redis Deployment
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ service.yaml     # Redis Service
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ pvc.yaml         # Redis PVC
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ secret.yaml      # Redis credentials
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ configmap.yaml   # Redis configuration
‚îÇ   ‚îú‚îÄ‚îÄ monitoring/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ servicemonitor.yaml # ServiceMonitor
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ podmonitor.yaml    # PodMonitor
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ prometheus-rules.yaml # Alert rules
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ grafana-dashboard.yaml # Grafana dashboard
‚îÇ   ‚îî‚îÄ‚îÄ tests/
‚îÇ       ‚îú‚îÄ‚îÄ test-connection.yaml  # Test pod –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ connectivity
‚îÇ       ‚îî‚îÄ‚îÄ test-database.yaml    # Test pod –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ database
‚îú‚îÄ‚îÄ charts/                   # –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –¥—Ä—É–≥–∏—Ö —á–∞—Ä—Ç–æ–≤
‚îÇ   ‚îú‚îÄ‚îÄ postgresql-*.tgz     # PostgreSQL chart (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
‚îÇ   ‚îî‚îÄ‚îÄ redis-*.tgz          # Redis chart (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
‚îî‚îÄ‚îÄ README.md                # –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è
```

### **Chart.yaml**

```yaml
apiVersion: v2
name: alert-history-go
description: A Helm chart for Alert History Service (Go version)
type: application
version: 0.1.0
appVersion: "1.0.0"
keywords:
  - alert
  - monitoring
  - history
  - go
  - kubernetes
home: https://github.com/your-org/alert-history
sources:
  - https://github.com/your-org/alert-history
maintainers:
  - name: Your Team
    email: team@yourcompany.com
dependencies:
  - name: postgresql
    version: "12.x.x"
    repository: "https://charts.bitnami.com/bitnami"
    condition: postgresql.enabled
  - name: redis
    version: "17.x.x"
    repository: "https://charts.bitnami.com/bitnami"
    condition: redis.enabled
```

## üîÑ **–ö–û–ú–ü–û–ù–ï–ù–¢–´ –°–ò–°–¢–ï–ú–´**

### **1. Application Deployment**

#### **Deployment Template**
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: {{ include "alert-history-go.fullname" . }}
  labels:
    {{- include "alert-history-go.labels" . | nindent 4 }}
spec:
  replicas: {{ .Values.replicaCount }}
  selector:
    matchLabels:
      {{- include "alert-history-go.selectorLabels" . | nindent 6 }}
  template:
    metadata:
      labels:
        {{- include "alert-history-go.selectorLabels" . | nindent 8 }}
    spec:
      containers:
        - name: {{ .Chart.Name }}
          image: "{{ .Values.image.repository }}:{{ .Values.image.tag }}"
          imagePullPolicy: {{ .Values.image.pullPolicy }}
          ports:
            - name: http
              containerPort: 8080
              protocol: TCP
          env:
            {{- range .Values.env }}
            - name: {{ .name }}
              value: {{ .value | quote }}
            {{- end }}
            - name: DB_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: {{ include "alert-history-go.fullname" . }}-db
                  key: password
          livenessProbe:
            httpGet:
              path: /health
              port: http
            initialDelaySeconds: 30
            periodSeconds: 10
            timeoutSeconds: 5
            failureThreshold: 3
          readinessProbe:
            httpGet:
              path: /ready
              port: http
            initialDelaySeconds: 5
            periodSeconds: 5
            timeoutSeconds: 3
            failureThreshold: 3
          resources:
            {{- toYaml .Values.resources | nindent 12 }}
          securityContext:
            {{- toYaml .Values.securityContext | nindent 12 }}
      {{- with .Values.nodeSelector }}
      nodeSelector:
        {{- toYaml . | nindent 8 }}
      {{- end }}
      {{- with .Values.affinity }}
      affinity:
        {{- toYaml . | nindent 8 }}
      {{- end }}
      {{- with .Values.tolerations }}
      tolerations:
        {{- toYaml . | nindent 8 }}
      {{- end }}
```

#### **Service Template**
```yaml
apiVersion: v1
kind: Service
metadata:
  name: {{ include "alert-history-go.fullname" . }}
  labels:
    {{- include "alert-history-go.labels" . | nindent 4 }}
spec:
  type: {{ .Values.service.type }}
  ports:
    - port: {{ .Values.service.port }}
      targetPort: http
      protocol: TCP
      name: http
  selector:
    {{- include "alert-history-go.selectorLabels" . | nindent 4 }}
```

### **2. PostgreSQL StatefulSet**

#### **StatefulSet Template**
```yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: {{ include "alert-history-go.fullname" . }}-postgresql
  labels:
    {{- include "alert-history-go.labels" . | nindent 4 }}
    app.kubernetes.io/component: postgresql
spec:
  serviceName: {{ include "alert-history-go.fullname" . }}-postgresql
  replicas: 1
  selector:
    matchLabels:
      {{- include "alert-history-go.selectorLabels" . | nindent 6 }}
      app.kubernetes.io/component: postgresql
  template:
    metadata:
      labels:
        {{- include "alert-history-go.selectorLabels" . | nindent 8 }}
        app.kubernetes.io/component: postgresql
    spec:
      containers:
        - name: postgresql
          image: "{{ .Values.postgresql.image.repository }}:{{ .Values.postgresql.image.tag }}"
          ports:
            - name: postgresql
              containerPort: 5432
              protocol: TCP
          env:
            - name: POSTGRESQL_DATABASE
              value: {{ .Values.postgresql.auth.database | quote }}
            - name: POSTGRESQL_USERNAME
              value: {{ .Values.postgresql.auth.username | quote }}
            - name: POSTGRESQL_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: {{ include "alert-history-go.fullname" . }}-postgresql
                  key: password
          volumeMounts:
            - name: data
              mountPath: /bitnami/postgresql
          livenessProbe:
            exec:
              command:
                - /bin/sh
                - -c
                - exec pg_isready -U {{ .Values.postgresql.auth.username }} -h 127.0.0.1 -p 5432
            initialDelaySeconds: 30
            periodSeconds: 10
            timeoutSeconds: 5
            failureThreshold: 6
          readinessProbe:
            exec:
              command:
                - /bin/sh
                - -c
                - exec pg_isready -U {{ .Values.postgresql.auth.username }} -h 127.0.0.1 -p 5432
            initialDelaySeconds: 5
            periodSeconds: 5
            timeoutSeconds: 3
            failureThreshold: 3
          resources:
            {{- toYaml .Values.postgresql.resources | nindent 12 }}
      volumes:
        - name: data
          persistentVolumeClaim:
            claimName: {{ include "alert-history-go.fullname" . }}-postgresql
  volumeClaimTemplates:
    - metadata:
        name: data
      spec:
        accessModes:
          - ReadWriteOnce
        resources:
          requests:
            storage: {{ .Values.postgresql.persistence.size }}
        {{- if .Values.postgresql.persistence.storageClass }}
        storageClassName: {{ .Values.postgresql.persistence.storageClass }}
        {{- end }}
```

### **3. Redis Deployment**

#### **Redis Deployment Template**
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: {{ include "alert-history-go.fullname" . }}-redis
  labels:
    {{- include "alert-history-go.labels" . | nindent 4 }}
    app.kubernetes.io/component: redis
spec:
  replicas: 1
  selector:
    matchLabels:
      {{- include "alert-history-go.selectorLabels" . | nindent 6 }}
      app.kubernetes.io/component: redis
  template:
    metadata:
      labels:
        {{- include "alert-history-go.selectorLabels" . | nindent 8 }}
        app.kubernetes.io/component: redis
    spec:
      containers:
        - name: redis
          image: "{{ .Values.redis.image.repository }}:{{ .Values.redis.image.tag }}"
          ports:
            - name: redis
              containerPort: 6379
              protocol: TCP
          env:
            - name: REDIS_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: {{ include "alert-history-go.fullname" . }}-redis
                  key: password
          command:
            - redis-server
            - --requirepass $(REDIS_PASSWORD)
            - --appendonly yes
          volumeMounts:
            - name: data
              mountPath: /data
          livenessProbe:
            tcpSocket:
              port: redis
            initialDelaySeconds: 30
            periodSeconds: 10
            timeoutSeconds: 5
          readinessProbe:
            tcpSocket:
              port: redis
            initialDelaySeconds: 5
            periodSeconds: 5
            timeoutSeconds: 3
          resources:
            {{- toYaml .Values.redis.resources | nindent 12 }}
      volumes:
        - name: data
          persistentVolumeClaim:
            claimName: {{ include "alert-history-go.fullname" . }}-redis
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: {{ include "alert-history-go.fullname" . }}-redis
  labels:
    {{- include "alert-history-go.labels" . | nindent 4 }}
    app.kubernetes.io/component: redis
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: {{ .Values.redis.persistence.size }}
  {{- if .Values.redis.persistence.storageClass }}
  storageClassName: {{ .Values.redis.persistence.storageClass }}
  {{- end }}
```

### **4. Monitoring & Observability**

#### **ServiceMonitor Template**
```yaml
{{- if .Values.monitoring.enabled }}
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: {{ include "alert-history-go.fullname" . }}
  labels:
    {{- include "alert-history-go.labels" . | nindent 4 }}
    app.kubernetes.io/component: monitoring
spec:
  selector:
    matchLabels:
      {{- include "alert-history-go.selectorLabels" . | nindent 6 }}
  endpoints:
    - port: http
      path: /metrics
      interval: 30s
      scrapeTimeout: 10s
  namespaceSelector:
    matchNames:
      - {{ .Release.Namespace }}
{{- end }}
```

#### **Prometheus Rules**
```yaml
{{- if .Values.monitoring.enabled }}
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: {{ include "alert-history-go.fullname" . }}-alerts
  labels:
    {{- include "alert-history-go.labels" . | nindent 4 }}
    app.kubernetes.io/component: monitoring
spec:
  groups:
    - name: alert-history-go
      rules:
        - alert: AlertHistoryGoDown
          expr: up{job="{{ include "alert-history-go.fullname" . }}"} == 0
          for: 5m
          labels:
            severity: critical
          annotations:
            summary: "Alert History Go is down"
            description: "Alert History Go has been down for more than 5 minutes."

        - alert: AlertHistoryGoHighCPU
          expr: rate(container_cpu_usage_seconds_total{pod=~"{{ include "alert-history-go.fullname" . }}-.*"}[5m]) > 0.8
          for: 10m
          labels:
            severity: warning
          annotations:
            summary: "High CPU usage on Alert History Go"
            description: "CPU usage is above 80% for more than 10 minutes."
{{- end }}
```

### **5. Scaling & High Availability**

#### **HorizontalPodAutoscaler**
```yaml
{{- if .Values.hpa.enabled }}
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: {{ include "alert-history-go.fullname" . }}
  labels:
    {{- include "alert-history-go.labels" . | nindent 4 }}
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: {{ include "alert-history-go.fullname" . }}
  minReplicas: {{ .Values.hpa.minReplicas }}
  maxReplicas: {{ .Values.hpa.maxReplicas }}
  metrics:
    {{- if .Values.hpa.targetCPUUtilizationPercentage }}
    - type: Resource
      resource:
        name: cpu
        target:
          type: Utilization
          averageUtilization: {{ .Values.hpa.targetCPUUtilizationPercentage }}
    {{- end }}
    {{- if .Values.hpa.targetMemoryUtilizationPercentage }}
    - type: Resource
      resource:
        name: memory
        target:
          type: Utilization
          averageUtilization: {{ .Values.hpa.targetMemoryUtilizationPercentage }}
    {{- end }}
{{- end }}
```

#### **PodDisruptionBudget**
```yaml
{{- if .Values.pdb.enabled }}
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: {{ include "alert-history-go.fullname" . }}
  labels:
    {{- include "alert-history-go.labels" . | nindent 4 }}
spec:
  {{- if .Values.pdb.minAvailable }}
  minAvailable: {{ .Values.pdb.minAvailable }}
  {{- end }}
  {{- if .Values.pdb.maxUnavailable }}
  maxUnavailable: {{ .Values.pdb.maxUnavailable }}
  {{- end }}
  selector:
    matchLabels:
      {{- include "alert-history-go.selectorLabels" . | nindent 4 }}
{{- end }}
```

## üîí **–ë–ï–ó–û–ü–ê–°–ù–û–°–¢–¨**

### **Network Policies**
```yaml
{{- if .Values.networkPolicy.enabled }}
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: {{ include "alert-history-go.fullname" . }}
  labels:
    {{- include "alert-history-go.labels" . | nindent 4 }}
spec:
  podSelector:
    matchLabels:
      {{- include "alert-history-go.selectorLabels" . | nindent 4 }}
  policyTypes:
    - Ingress
    - Egress
  ingress:
    # Allow traffic from ingress controller
    - from:
        - namespaceSelector:
            matchLabels:
              name: ingress-nginx
      ports:
        - protocol: TCP
          port: 8080
    # Allow traffic from Prometheus
    - from:
        - namespaceSelector:
            matchLabels:
              name: monitoring
      ports:
        - protocol: TCP
          port: 8080
  egress:
    # Allow DNS resolution
    - to: []
      ports:
        - protocol: UDP
          port: 53
    # Allow traffic to PostgreSQL
    - to:
        - podSelector:
            matchLabels:
              app.kubernetes.io/name: postgresql
      ports:
        - protocol: TCP
          port: 5432
    # Allow traffic to Redis
    - to:
        - podSelector:
            matchLabels:
              app.kubernetes.io/name: redis
      ports:
        - protocol: TCP
          port: 6379
{{- end }}
```

### **Security Contexts**
```yaml
spec:
  securityContext:
    runAsNonRoot: true
    runAsUser: 1000
    runAsGroup: 1000
    fsGroup: 1000
  containers:
    - securityContext:
        allowPrivilegeEscalation: false
        readOnlyRootFilesystem: true
        runAsNonRoot: true
        runAsUser: 1000
        capabilities:
          drop:
            - ALL
```

## üìä **–ö–û–ù–§–ò–ì–£–†–ê–¶–ò–ò –î–õ–Ø –†–ê–ó–ù–´–• –°–†–ï–î**

### **Development Environment**
```yaml
# values-dev.yaml
replicaCount: 1

image:
  tag: "dev"
  pullPolicy: Always

postgresql:
  persistence:
    enabled: false  # Use emptyDir for dev

redis:
  persistence:
    enabled: false  # Use emptyDir for dev

ingress:
  enabled: false  # No ingress in dev

monitoring:
  enabled: false  # No monitoring in dev

hpa:
  enabled: false  # No autoscaling in dev

resources:
  requests:
    memory: 128Mi
    cpu: 100m
  limits:
    memory: 256Mi
    cpu: 200m
```

### **Staging Environment**
```yaml
# values-staging.yaml
replicaCount: 2

ingress:
  enabled: true
  hosts:
    - host: alert-history.staging.yourcompany.com
  tls:
    - secretName: alert-history-staging-tls
      hosts:
        - alert-history.staging.yourcompany.com

postgresql:
  persistence:
    size: 20Gi
    storageClass: "standard"

redis:
  persistence:
    size: 2Gi
    storageClass: "standard"

monitoring:
  enabled: true

hpa:
  enabled: true
  minReplicas: 2
  maxReplicas: 5
```

### **Production Environment**
```yaml
# values-prod.yaml
replicaCount: 5

ingress:
  enabled: true
  hosts:
    - host: alert-history.yourcompany.com
  tls:
    - secretName: alert-history-prod-tls
      hosts:
        - alert-history.yourcompany.com

postgresql:
  persistence:
    size: 100Gi
    storageClass: "fast-ssd"

redis:
  persistence:
    size: 10Gi
    storageClass: "fast-ssd"

monitoring:
  enabled: true

hpa:
  enabled: true
  minReplicas: 5
  maxReplicas: 20

pdb:
  enabled: true
  minAvailable: 3

networkPolicy:
  enabled: true

securityContext:
  runAsNonRoot: true
  runAsUser: 1000
  runAsGroup: 1000

resources:
  requests:
    memory: 512Mi
    cpu: 500m
  limits:
    memory: 1Gi
    cpu: 1000m
```

## üîß **HELPER FUNCTIONS**

### **_helpers.tpl**
```go
{{/*
Expand the name of the chart.
*/}}
{{- define "alert-history-go.name" -}}
{{- default .Chart.Name .Values.nameOverride | trunc 63 | trimSuffix "-" }}
{{- end }}

{{/*
Create a default fully qualified app name.
*/}}
{{- define "alert-history-go.fullname" -}}
{{- if .Values.fullnameOverride }}
{{- .Values.fullnameOverride | trunc 63 | trimSuffix "-" }}
{{- else }}
{{- $name := default .Chart.Name .Values.nameOverride }}
{{- if contains $name .Release.Name }}
{{- .Release.Name | trunc 63 | trimSuffix "-" }}
{{- else }}
{{- printf "%s-%s" .Release.Name $name | trunc 63 | trimSuffix "-" }}
{{- end }}
{{- end }}
{{- end }}

{{/*
Create chart name and version as used by the chart label.
*/}}
{{- define "alert-history-go.chart" -}}
{{- printf "%s-%s" .Chart.Name .Chart.Version | replace "+" "_" | trunc 63 | trimSuffix "-" }}
{{- end }}

{{/*
Common labels
*/}}
{{- define "alert-history-go.labels" -}}
helm.sh/chart: {{ include "alert-history-go.chart" . }}
{{ include "alert-history-go.selectorLabels" . }}
{{- if .Chart.AppVersion }}
app.kubernetes.io/version: {{ .Chart.AppVersion | quote }}
{{- end }}
app.kubernetes.io/managed-by: {{ .Release.Service }}
{{- end }}

{{/*
Selector labels
*/}}
{{- define "alert-history-go.selectorLabels" -}}
app.kubernetes.io/name: {{ include "alert-history-go.name" . }}
app.kubernetes.io/instance: {{ .Release.Name }}
{{- end }}
```

## üß™ **–¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï**

### **Test Templates**
```yaml
# templates/tests/test-connection.yaml
apiVersion: v1
kind: Pod
metadata:
  name: "{{ include "alert-history-go.fullname" . }}-test-connection"
  labels:
    {{- include "alert-history-go.labels" . | nindent 4 }}
  annotations:
    "helm.sh/hook": test
spec:
  restartPolicy: Never
  containers:
    - name: wget
      image: busybox
      command: ['wget']
      args:  ['{{ include "alert-history-go.fullname" . }}:{{ .Values.service.port }}/health']
```

### **Database Connectivity Test**
```yaml
# templates/tests/test-database.yaml
apiVersion: v1
kind: Pod
metadata:
  name: "{{ include "alert-history-go.fullname" . }}-test-database"
  labels:
    {{- include "alert-history-go.labels" . | nindent 4 }}
  annotations:
    "helm.sh/hook": test
spec:
  restartPolicy: Never
  containers:
    - name: postgresql-client
      image: postgres:15-alpine
      env:
        - name: PGPASSWORD
          valueFrom:
            secretKeyRef:
              name: {{ include "alert-history-go.fullname" . }}-postgresql
              key: password
      command:
        - psql
        - -h
        - {{ include "alert-history-go.fullname" . }}-postgresql
        - -U
        - {{ .Values.postgresql.auth.username }}
        - -d
        - {{ .Values.postgresql.auth.database }}
        - -c
        - "SELECT 1;"
```

## üöÄ **DEPLOYMENT PROCESS**

### **Installation**
```bash
# Add Helm repository (if needed)
helm repo add your-repo https://charts.yourcompany.com
helm repo update

# Install in development
helm install alert-history-dev ./alert-history-go \
  -f values-dev.yaml \
  -n development

# Install in staging
helm install alert-history-staging ./alert-history-go \
  -f values-staging.yaml \
  -n staging

# Install in production
helm install alert-history-prod ./alert-history-go \
  -f values-prod.yaml \
  -n production
```

### **Upgrade**
```bash
# Upgrade with new values
helm upgrade alert-history-prod ./alert-history-go \
  -f values-prod.yaml \
  --set image.tag=v1.2.0

# Rollback if needed
helm rollback alert-history-prod 1
```

### **Uninstallation**
```bash
# Uninstall (keeps PVCs)
helm uninstall alert-history-prod

# Remove PVCs if needed
kubectl delete pvc -l app.kubernetes.io/instance=alert-history-prod
```

## üìà **MONITORING & ALERTING**

### **Key Metrics to Monitor**
- **Application Health**: HTTP 200 responses, latency < 100ms
- **Database Performance**: Connection pool utilization < 80%
- **Resource Usage**: CPU < 70%, Memory < 80%
- **Error Rates**: < 0.1% 5xx errors
- **Pod Status**: All pods ready, no restarts

### **Grafana Dashboard**
```json
{
  "dashboard": {
    "title": "Alert History Go",
    "panels": [
      {
        "title": "HTTP Request Rate",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(http_requests_total{job=\"alert-history-go\"}[5m])",
            "legendFormat": "Requests/sec"
          }
        ]
      },
      {
        "title": "HTTP Request Duration",
        "type": "heatmap",
        "targets": [
          {
            "expr": "rate(http_request_duration_seconds_bucket{job=\"alert-history-go\"}[5m])",
            "legendFormat": "{{le}}"
          }
        ]
      },
      {
        "title": "Database Connections",
        "type": "graph",
        "targets": [
          {
            "expr": "pg_stat_activity_count{datname=\"alerthistory\"}",
            "legendFormat": "Active connections"
          }
        ]
      }
    ]
  }
}
```

## üéØ **SUCCESS CRITERIA**

### **Functional Requirements**
- ‚úÖ **Deployment Success**: All pods start and pass health checks
- ‚úÖ **Service Connectivity**: All services are accessible
- ‚úÖ **Database Access**: Application can connect to PostgreSQL
- ‚úÖ **Cache Access**: Application can connect to Redis
- ‚úÖ **External Access**: Ingress routes traffic correctly

### **Performance Requirements**
- ‚úÖ **Startup Time**: < 60 seconds for full deployment
- ‚úÖ **Resource Usage**: Within defined limits
- ‚úÖ **Scalability**: HPA works correctly
- ‚úÖ **High Availability**: PDB prevents disruptions

### **Operational Requirements**
- ‚úÖ **Monitoring**: Metrics collected and alerts configured
- ‚úÖ **Security**: Network policies and security contexts applied
- ‚úÖ **Backups**: PVCs configured for persistence
- ‚úÖ **Updates**: Rolling updates work without downtime

### **Quality Requirements**
- ‚úÖ **Helm Validation**: Chart passes `helm lint`
- ‚úÖ **Template Rendering**: All templates render correctly
- ‚úÖ **Documentation**: Complete README and usage examples
- ‚úÖ **Testing**: Test pods validate functionality

This comprehensive Helm chart design provides a production-ready deployment solution for Alert History Service with full support for scalability, monitoring, security, and operational excellence.
